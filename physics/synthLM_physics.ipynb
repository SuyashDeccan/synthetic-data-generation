{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents...\n",
      "Loaded 6 documents\n",
      "\n",
      "Extracting topics and key concepts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 14:12:29,833 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw output: {\n",
      "  \"topics\": [\n",
      "    \"Atomic and Nuclear Physics\",\n",
      "    \"Particle Scattering and Rutherford-Bohr Model\",\n",
      "    \"Spectral Series and Atomic Transitions\",\n",
      "    \"Wave-Particle Duality and Schrödinger Equation\",\n",
      "    \"Atom Properties and Spectroscopy\",\n",
      "    \"Molecules, Crystals, and Vibrations\",\n",
      "    \"Elementary Particles and Quantum Numbers\",\n",
      "    \"Nuclear Reactions and Radioactivity\",\n",
      "    \"Nuclear Fission and Chain Reactions\",\n",
      "    \"Elementary Atomic, Nuclear, and Particle Processes\"\n",
      "  ],\n",
      "  \"key_concepts\": [\n",
      "    \"Coulomb deflection angle and Rutherford scattering formula\",\n",
      "    \"Spectral series of hydrogen (Lyman, Balmer, Paschen) and Rydberg formula\",\n",
      "    \"Bohr model: hydrogen atom radius, energy, and spectral lines\",\n",
      "    \"Quantum wave properties: de Broglie wavelength, uncertainty principle\",\n",
      "    \"Schrödinger equations, barrier penetration, and wave functions\",\n",
      "    \"Atomic term symbols, Hund rules, Zeeman effect, and spectral line splitting\",\n",
      "    \"Rotational and vibrational energy levels of diatomic molecules, natural frequencies, and spectrum of Raman scattering\",\n",
      "    \"Quantum numbers (Q, L, S, B, T, Y), atomic term designations, magnetic moments\",\n",
      "    \"Radioactive decay law, activity, half-life, decay chains, and isotope dating\",\n",
      "    \"Nuclear binding energy, reaction energetics, threshold energy, and fission process\",\n",
      "    \"Elementary particle properties: energy, momentum, quantum numbers, reaction thresholds\",\n",
      "    \"Conservation laws in particle physics: charge, lepton number, baryon number\",\n",
      "    \"Nuclear reactions: elastic scattering, fusion, fission, beta decay, gamma decay\",\n",
      "    \"Relativistic effects on particles: kinetic energy, invariant mass, threshold calculations\",\n",
      "    \"Quantum behavior of particles in potential wells, oscillators, and crystal lattices\",\n",
      "    \"Demonstration of interference, diffraction, and spectral line splitting phenomena\"\n",
      "  ]\n",
      "}\n",
      "Successfully extracted 10 topics and 16 key concepts from Irodov-Problems_in_General_Physics-253-287.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 14:12:35,791 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw output: {\n",
      "  \"topics\": [\n",
      "    \"Optics Fundamentals\",\n",
      "    \"Photometry and Geometrical Optics\",\n",
      "    \"Interference of Light\",\n",
      "    \"Diffraction of Light\",\n",
      "    \"Dispersion and Absorption of Light\",\n",
      "    \"Optics of Moving Sources\",\n",
      "    \"Thermal Radiation and Quantum Nature of Light\",\n",
      "    \"Polarization of Light\",\n",
      "    \"X-ray and Gamma-ray Optics\",\n",
      "    \"Quantum and Relativistic Optics\",\n",
      "    \"Optical Instruments and Systems\"\n",
      "  ],\n",
      "  \"key_concepts\": [\n",
      "    \"Spectral response of the human eye\",\n",
      "    \"Luminous intensity, illuminance, luminosity, luminance\",\n",
      "    \"Refractive angles, deviation in prisms\",\n",
      "    \"Spherical mirrors and lens equations, optical power, principal planes\",\n",
      "    \"Fresnel zones and interference fringes (Newton's rings, Lloyd's mirror, Fresnel zones)\",\n",
      "    \"Diffraction grating conditions, resolving power, angular dispersion\",\n",
      "    \"Rayleigh's formula, diffraction minima and maxima, Bragg's law\",\n",
      "    \"Polarization: degrees of polarization, Malus's law, Brewster's angle, Fresnel equations\",\n",
      "    \"Vavilov-Cherenkov effect, Doppler effect for light, relativistic effects\",\n",
      "    \"Quantitative description of thermal radiation: Wien's law, Stefan-Boltzmann law, Planck's formula\",\n",
      "    \"Photoelectric effect, Compton scattering, quantum nature of light\",\n",
      "    \"Electromagnetic wave propagation in dispersive, absorbing, and moving media\",\n",
      "    \"Optical properties of crystalline and anisotropic materials, birefringence\",\n",
      "    \"Interference fringes, Fabry-Perot etalon, diffraction patterns\",\n",
      "    \"X-ray diffraction, relating crystal structure to diffraction maxima\",\n",
      "    \"Optical instruments: microscopes, telescopes, spectrometers, lenses, mirrors\"\n",
      "  ]\n",
      "}\n",
      "Successfully extracted 11 topics and 16 key concepts from Irodov-Problems_in_General_Physics-206-252.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 14:12:39,865 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw output: {\n",
      "  \"topics\": [\n",
      "    \"Oscillations and Waves\",\n",
      "    \"Mechanical Oscillations\",\n",
      "    \"Electrical Oscillations and AC Circuits\",\n",
      "    \"Elastic Waves and Acoustics\",\n",
      "    \"Electromagnetic Waves and Radiation\"\n",
      "  ],\n",
      "  \"key_concepts\": [\n",
      "    \"Harmonic motion equations and solutions\",\n",
      "    \"Damped, forced, and superimposed oscillations\",\n",
      "    \"Wave equations and propagation velocities\",\n",
      "    \"Standing waves and phase relationships\",\n",
      "    \"Energy density, flow, and damping in waves\",\n",
      "    \"Doppler effects and phase differences\",\n",
      "    \"Oscillations in various mechanical systems (poles, strings, pendulums, rods, springs)\",\n",
      "    \"Resonance phenomena and quality factor\",\n",
      "    \"Damped and forced oscillations in electrical circuits\",\n",
      "    \"Resonance frequency, power, and damping in RLC circuits\",\n",
      "    \"Electromagnetic wave properties: electric and magnetic field components, energy flow, and polarization\",\n",
      "    \"Differences between longitudinal and transverse waves\",\n",
      "    \"Reflection, diffraction, and interference of waves\",\n",
      "    \"Acoustic phenomena: sound intensity, loudness, Doppler effect in sound\",\n",
      "    \"Wave energy conversion and radiation power for electric and magnetic dipoles\",\n",
      "    \"Propagation of electromagnetic waves in various media\"\n",
      "  ]\n",
      "}\n",
      "Successfully extracted 5 topics and 16 key concepts from Irodov-Problems_in_General_Physics-173-205.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 14:12:46,170 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw output: {\n",
      "  \"topics\": [\n",
      "    \"Classical Mechanics Fundamentals\",\n",
      "    \"Kinematics of Particles and Rigid Bodies\",\n",
      "    \"Dynamics of Particles and Rigid Bodies\",\n",
      "    \"Conservation Laws in Mechanics\",\n",
      "    \"Universal Gravitation and Celestial Mechanics\",\n",
      "    \"Elastic and Deformational Properties of Solids\",\n",
      "    \"Hydrodynamics of Ideal and Viscous Fluids\",\n",
      "    \"Relativistic Mechanics and Special Relativity\"\n",
      "  ],\n",
      "  \"key_concepts\": [\n",
      "    \"Velocity, acceleration, and trajectory analysis\",\n",
      "    \"Angular velocity and acceleration of rigid bodies\",\n",
      "    \"Relation between linear and angular kinematic quantities\",\n",
      "    \"Newton's Second Law and equations of motion\",\n",
      "    \"Dynamics in non-inertial reference frames\",\n",
      "    \"Work-energy principle, potential energy, and power\",\n",
      "    \"Conservation of energy, linear, and angular momentum\",\n",
      "    \"Universal gravitation law, planetary motion, and Kepler's laws\",\n",
      "    \"Elastic deformation, stress-strain relationships, and elasticity constants\",\n",
      "    \"Fluid flow equations, Bernoulli's principle, Reynolds and Poiseuille laws\",\n",
      "    \"Viscous forces, laminar versus turbulent flow, and flow of viscous fluids\",\n",
      "    \"Relativistic kinematics: Lorentz contraction, transformation of space-time, relativistic mass, and energy\",\n",
      "    \"Relativistic velocity addition and invariants in special relativity\",\n",
      "    \"Relativistic collisions, energy-momentum relation, and their invariants\"\n",
      "  ]\n",
      "}\n",
      "Successfully extracted 8 topics and 14 key concepts from Irodov-Problems_in_General_Physics-1-64.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 14:12:56,277 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw output: {\n",
      "  \"topics\": [\n",
      "    \"Thermodynamics\",\n",
      "    \"Gas Laws and Equations of State\",\n",
      "    \"Processes involving Ideal and Real Gases\",\n",
      "    \"Kinetic Theory of Gases\",\n",
      "    \"Second Law of Thermodynamics\",\n",
      "    \"Entropy and Cycles\",\n",
      "    \"Phase Transformations\",\n",
      "    \"Liquid Surface and Capillary Effects\",\n",
      "    \"Transport Phenomena in Gases\",\n",
      "    \"Vaporization and Liquid-Gas Equilibrium\",\n",
      "    \"Phase Transitions and Critical State\",\n",
      "    \"Wave Propagation and Diffusion in Gases\",\n",
      "    \"Transport Coefficients: Diffusion, Viscosity, Heat Conductivity\",\n",
      "    \"Heat Transfer and Thermal Conductivity\",\n",
      "    \"Relativity of Molecular Speeds\",\n",
      "    \"Molecular Distributions (Maxwell and Boltzmann)\",\n",
      "    \"Pressure, Temperature, Density Relations\",\n",
      "    \"Work and Heat in Thermodynamic Cycles\",\n",
      "    \"Van der Waals Equation and Critical Constants\",\n",
      "    \"Processes in Liquids and Capillary Phenomena\",\n",
      "    \"Phase Change Dynamics\",\n",
      "    \"Surface Tension and Capillary Action\",\n",
      "    \"Vapor Pressure and Condensation\",\n",
      "    \"Latent Heats and Entropy Changes\",\n",
      "    \"Surface Energy and Free Energy of Interfaces\",\n",
      "    \"Thermal Expansion, Contraction, and Fracture\",\n",
      "    \"Diffusion and Molecular Transport\"\n",
      "  ],\n",
      "  \"key_concepts\": [\n",
      "    \"Ideal gas law: pV = RT/M\",\n",
      "    \"Barometric pressure variation: P = P0 * exp(-Mgh/RT)\",\n",
      "    \"Van der Waals equation for real gases\",\n",
      "    \"Internal energy of ideal and Van der Waals gases\",\n",
      "    \"First law of thermodynamics: dQ = dU + pdV\",\n",
      "    \"Work done by gas: W = p * dV\",\n",
      "    \"Heat capacities at constant volume and pressure\",\n",
      "    \"Polytropic processes: pV^n = const\",\n",
      "    \"Maxwell distribution of molecular velocities\",\n",
      "    \"Most probable, mean, and RMS molecular velocities\",\n",
      "    \"Entropy change and statistical interpretation\",\n",
      "    \"Carnot cycle efficiency: η = 1 - T_cold/T_hot\",\n",
      "    \"Clausius inequality and entropy production\",\n",
      "    \"Phase equilibrium: Clausius-Clapeyron equation\",\n",
      "    \"Latent heats of vaporization and sublimation\",\n",
      "    \"Surface tension and Laplace's law\",\n",
      "    \"Capillary pressure and surface free energy\",\n",
      "    \"Surface free energy: dF = a dS\",\n",
      "    \"Vapor pressure dependencies and critical point parameters\",\n",
      "    \"Transport coefficients: diffusion, viscosity, thermal conductivity\",\n",
      "    \"Mean free path and collision frequency\",\n",
      "    \"Diffusion processes and molecular flux\",\n",
      "    \"Heat conduction in solids and gases\",\n",
      "    \"Thermal expansion and temperature gradients\",\n",
      "    \"Surface phenomena in liquids: wetting, meniscus shape\",\n",
      "    \"Capillary rise and contact angles\",\n",
      "    \"Phase transformations: boiling, melting, sublimation\",\n",
      "    \"Effect of pressure and temperature on phase equilibria\",\n",
      "    \"Analytical relations for phase change and critical constants\",\n",
      "    \"Entropy variations during phase transitions\"\n",
      "  ]\n",
      "}\n",
      "Successfully extracted 27 topics and 30 key concepts from Irodov-Problems_in_General_Physics-65-94.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 14:13:02,067 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw output: {\n",
      "  \"topics\": [\n",
      "    \"Electrodynamics\",\n",
      "    \"Constant Electric Fields\",\n",
      "    \"Electrostatic Fields and Potentials\",\n",
      "    \"Conductors and Dielectrics in Electric Fields\",\n",
      "    \"Capacitance and Electric Energy\",\n",
      "    \"Electric Currents and Circuit Laws\",\n",
      "    \"Magnetics\",\n",
      "    \"Electromagnetic Induction\",\n",
      "    \"Electromagnetic Wave Transformation\",\n",
      "    \"Motion of Charged Particles in Fields\",\n",
      "    \"Magnetohydrodynamics and Magnetic Forces\",\n",
      "    \"Electromagnetic Devices and Applications\",\n",
      "    \"Relativistic Effects in Electrodynamics\"\n",
      "  ],\n",
      "  \"key_concepts\": [\n",
      "    \"Electric field strength and potential of point charges and dipoles\",\n",
      "    \"Gauss's theorem and electric flux\",\n",
      "    \"Boundary conditions between different dielectric media\",\n",
      "    \"Electric field and potential of charged conductors, rings, spheres, and cylinders\",\n",
      "    \"Capacitance calculations for various geometries and media\",\n",
      "    \"Electric field energy density and energy stored in capacitors\",\n",
      "    \"Ohm's law in inhomogeneous media and circuit analysis\",\n",
      "    \"Magnetic field of point charges, currents, and magnetic dipoles\",\n",
      "    \"Biot-Savart law and Ampère's force law\",\n",
      "    \"Magnetic vector potential and magnetic energy\",\n",
      "    \"Electromagnetic induction: Faraday's law, flux, and emf\",\n",
      "    \"Transformations of electric and magnetic fields between inertial frames\",\n",
      "    \"Motion of charged particles in electric and magnetic fields, including relativistic effects\",\n",
      "    \"Cyclotron and betatron principles for particle acceleration\",\n",
      "    \"Electromagnetic wave phenomena, induction in loops, and field transformations\"\n",
      "  ]\n",
      "}\n",
      "Successfully extracted 13 topics and 15 key concepts from Irodov-Problems_in_General_Physics-112-172.pdf\n",
      "Saved document extractions to output_irodov/document_extractions.json\n",
      "\n",
      "Building concept graph...\n",
      "Graph built with 74 topics and 107 key concepts\n",
      "\n",
      "Sampling concept combinations...\n",
      "Sampling from 74 topics\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "from collections import Counter\n",
    "import networkx as nx\n",
    "import pdfplumber\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key from environment variable\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# -- Document Loading ------------------------------------------------------\n",
    "\n",
    "def load_docs_from_dir(dir_path):\n",
    "    \"\"\"\n",
    "    Load all .pdf files from a directory and extract their full text.\n",
    "    Returns a list of strings, one per PDF.\n",
    "    \"\"\"\n",
    "    docs = []\n",
    "    filenames = []\n",
    "    for filepath in glob.glob(os.path.join(dir_path, '*.pdf')):\n",
    "        try:\n",
    "            text_pages = []\n",
    "            with pdfplumber.open(filepath) as pdf:\n",
    "                for page in pdf.pages:\n",
    "                    text_pages.append(page.extract_text() or \"\")\n",
    "            full_text = \"\\n\".join(text_pages)\n",
    "            docs.append(full_text)\n",
    "            filenames.append(os.path.basename(filepath))\n",
    "        except Exception as e:\n",
    "            # skip unreadable PDFs\n",
    "            print(f\"Warning: could not load {filepath}: {e}\")\n",
    "    return docs, filenames\n",
    "\n",
    "# -- 1. Extract topics and key concepts -----------------------------------\n",
    "\n",
    "def extract_json_from_text(text):\n",
    "    \"\"\"Helper function to extract JSON content from markdown code blocks or raw text\"\"\"\n",
    "    # Try to extract JSON from markdown code blocks\n",
    "    json_match = re.search(r'```(?:json)?\\s*(.*?)\\s*```', text, re.DOTALL)\n",
    "    if json_match:\n",
    "        return json_match.group(1).strip()\n",
    "    \n",
    "    # If no code blocks, try to find JSON-like structures\n",
    "    json_match = re.search(r'(\\{.*\\})', text, re.DOTALL)\n",
    "    if json_match:\n",
    "        return json_match.group(1).strip()\n",
    "    \n",
    "    # Return original text if no JSON structure found\n",
    "    return text\n",
    "\n",
    "def extract_concepts_from_docs(doc_texts, filenames, model=\"gpt-4.1-nano\"):  \n",
    "    \"\"\"\n",
    "    Call OpenAI API to extract topics and key concepts from each document.\n",
    "    Returns list of dicts with keys 'topics' and 'key_concepts'.\n",
    "    \"\"\"\n",
    "    extractions = []\n",
    "    for i, text in enumerate(doc_texts):\n",
    "        filename = filenames[i] if i < len(filenames) else f\"doc_{i}\"\n",
    "        \n",
    "        prompt = (\n",
    "            \"Extract high-level topics and key concepts from the following document. \"\n",
    "            f\"Return JSON with keys 'topics' and 'key_concepts'.\\n\\n{text}\"\n",
    "        )\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert summarizer. Return your response as a JSON object with 'topics' and 'key_concepts' as arrays.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "        )\n",
    "        \n",
    "        output = response.choices[0].message.content\n",
    "        print(\"Raw output:\", output)\n",
    "        \n",
    "        try:\n",
    "            # Clean and extract JSON from the output\n",
    "            json_str = extract_json_from_text(output)\n",
    "            data = json.loads(json_str)\n",
    "            \n",
    "            # Ensure we have the expected keys\n",
    "            if \"topics\" in data and \"key_concepts\" in data:\n",
    "                extraction = {\n",
    "                    \"filename\": filename,\n",
    "                    \"topics\": data[\"topics\"],\n",
    "                    \"key_concepts\": data[\"key_concepts\"]\n",
    "                }\n",
    "                extractions.append(extraction)\n",
    "                print(f\"Successfully extracted {len(data['topics'])} topics and {len(data['key_concepts'])} key concepts from {filename}\")\n",
    "            else:\n",
    "                print(f\"Warning: Parsed JSON doesn't have expected keys: {data.keys()}\")\n",
    "                extractions.append({\n",
    "                    \"filename\": filename,\n",
    "                    \"topics\": [], \n",
    "                    \"key_concepts\": []\n",
    "                })\n",
    "                \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Failed to parse JSON: {e}\")\n",
    "            extractions.append({\n",
    "                \"filename\": filename,\n",
    "                \"topics\": [], \n",
    "                \"key_concepts\": []\n",
    "            })\n",
    "    \n",
    "    return extractions\n",
    "\n",
    "# -- 2. Construct the concept graph ----------------------------------------\n",
    "\n",
    "def build_concept_graph(extractions, eps=1e-6):\n",
    "    \"\"\"\n",
    "    Build a unified graph G where nodes are topics + key concepts and\n",
    "    edges weighted by log(freq+eps) based on co-occurrence in docs.\n",
    "    Returns: G (nx.Graph), topic_nodes, kc_nodes\n",
    "    \"\"\"\n",
    "    freq = Counter()\n",
    "    all_topics, all_kcs = set(), set()\n",
    "\n",
    "    for ex in extractions:\n",
    "        nodes = ex[\"topics\"] + ex[\"key_concepts\"]\n",
    "        for i in range(len(nodes)):\n",
    "            for j in range(i+1, len(nodes)):\n",
    "                u, v = sorted((nodes[i], nodes[j]))\n",
    "                freq[(u, v)] += 1\n",
    "        all_topics.update(ex[\"topics\"])\n",
    "        all_kcs.update(ex[\"key_concepts\"])\n",
    "\n",
    "    G = nx.Graph()\n",
    "    for (u, v), f in freq.items():\n",
    "        weight = math.log(f + eps)\n",
    "        G.add_edge(u, v, weight=weight)\n",
    "\n",
    "    print(f\"Graph built with {len(all_topics)} topics and {len(all_kcs)} key concepts\")\n",
    "    return G, all_topics, all_kcs\n",
    "\n",
    "# -- Helpers for sampling --------------------------------------------------\n",
    "\n",
    "def softmax(weights):\n",
    "    exps = [math.exp(w) for w in weights]\n",
    "    s = sum(exps) or 1.0\n",
    "    return [e/s for e in exps]\n",
    "\n",
    "\n",
    "def random_walk(G, start, steps):\n",
    "    \"\"\"\n",
    "    Random walk on graph G for given steps from 'start',\n",
    "    with transition probabilities via softmax over edge weights.\n",
    "    \"\"\"\n",
    "    path = [start]\n",
    "    current = start\n",
    "    for _ in range(steps):\n",
    "        nbrs = list(G[current])\n",
    "        if not nbrs:\n",
    "            break\n",
    "        weights = [G[current][n]['weight'] for n in nbrs]\n",
    "        probs = softmax(weights)\n",
    "        current = random.choices(nbrs, probs)[0]\n",
    "        path.append(current)\n",
    "    return path\n",
    "\n",
    "# -- 3. Concept combination sampling ---------------------------------------\n",
    "\n",
    "def sample_concept_combinations(\n",
    "    G, topic_nodes, kc_nodes,\n",
    "    num_samples=100,\n",
    "    topic_walk_steps=(1, 2),\n",
    "    kc_walk_steps=(3, 4)\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate sampled sets of topics and key concepts via multi-stage random walks.\n",
    "    Returns list of dicts: {'topics': set, 'key_concepts': set}\n",
    "    \"\"\"\n",
    "    # Safety check\n",
    "    if not topic_nodes:\n",
    "        print(\"Error: No topics found. Cannot sample combinations.\")\n",
    "        return []\n",
    "        \n",
    "    G_topic = G.subgraph(topic_nodes)\n",
    "    G_topic_kc = G.subgraph(topic_nodes | kc_nodes)\n",
    "    G_kc = G.subgraph(kc_nodes)\n",
    "    samples = []\n",
    "\n",
    "    topics_list = list(topic_nodes)\n",
    "    print(f\"Sampling from {len(topics_list)} topics\")\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        t0 = random.choice(topics_list)\n",
    "        t_steps = random.choice(topic_walk_steps)\n",
    "        topic_path = random_walk(G_topic, t0, t_steps)\n",
    "        sampled_topics = set(topic_path)\n",
    "\n",
    "        kc_cands = [nbr for t in sampled_topics for nbr in G_topic_kc[t] if nbr in kc_nodes]\n",
    "        if kc_cands:\n",
    "            k0 = random.choice(kc_cands)\n",
    "            k_steps = random.choice(kc_walk_steps)\n",
    "            kc_path = random_walk(G_kc, k0, k_steps)\n",
    "            sampled_kcs = set(kc_path)\n",
    "        else:\n",
    "            sampled_kcs = set()\n",
    "\n",
    "        samples.append({\n",
    "            \"topics\": list(sampled_topics),  # Convert sets to lists for JSON serialization\n",
    "            \"key_concepts\": list(sampled_kcs)\n",
    "        })\n",
    "    \n",
    "    return samples\n",
    "\n",
    "# -- 4. Question generation ------------------------------------------------\n",
    "\n",
    "def generate_questions_for_samples(combos, docs, extractions, model=\"gpt-4o\"):  \n",
    "    \"\"\"\n",
    "    For each sampled combo, pick two docs via Jaccard on concept sets,\n",
    "    then call LLM to generate questions.\n",
    "    Returns list of dicts: {'sample': combo, 'questions': [...]}.\n",
    "    \"\"\"\n",
    "    doc_concepts = [set(ex['topics'] + ex['key_concepts']) for ex in extractions]\n",
    "    # doc_concepts= doc_concepts[:1]\n",
    "    results = []\n",
    "    max_samples = 100\n",
    "    # combos = combos[:max_samples]\n",
    "    for i, combo in enumerate(combos):\n",
    "        combo_id = f\"combo_{i+1}\"\n",
    "        kg = set(combo['topics']) | set(combo['key_concepts'])\n",
    "        sims = []\n",
    "        for idx, dc in enumerate(doc_concepts):\n",
    "            inter = kg & dc\n",
    "            union = kg | dc\n",
    "            sims.append((len(inter) / (len(union) or 1), idx))\n",
    "        sims.sort(reverse=True)\n",
    "        top_idxs = [i for _, i in sims[:2]]\n",
    "        refs = [docs[i] for i in top_idxs]\n",
    "        ref_files = [extractions[i][\"filename\"] for i in top_idxs]\n",
    "        System_prompt =f\"\"\"\n",
    "Each question must follow these instructions:\n",
    "Model a Physical Scenario: Start from a real-world or idealized setup. Avoid abstract Physics problems or purely conceptual statements.\n",
    "Target a Solvable Quantity: Ask for a clear symbolic expression of a physical variable (e.g., tension, acceleration, energy).\n",
    "Force Multi-Step Reasoning: Ensure the question involves a sequence of physics laws, transformations, and derivations to reach the answer.\n",
    "Avoid Redundancy: Exclude extraneous details or variables that do not impact the final solution.\n",
    "Be Unique: Do not rephrase standard textbook problems; ensure originality and complexity.\n",
    "Single solution: Expect a single symbolic expression, unambiguous, presented in LaTeX. Multiple equivalent algebraic forms are allowed. No equations or floating-point approximations.\n",
    "Use rigorous, concise phrasing.\n",
    "Avoid colloquial or ambiguous terminology.\n",
    "Units must be consistent; symbols should follow standard notation.\n",
    "\"\"\"\n",
    "        prompt = (\n",
    "            f\"Generate a set of difficult Physics questions based on the following:\\n\"\n",
    "            \n",
    "            f\"Topics: {combo['topics']}\\n\"\n",
    "            f\"Key Concepts: {combo['key_concepts']}\\n\"\n",
    "            f\"Reference Doc 1:\\n{refs[0]}\\n\"\n",
    "        )\n",
    "        if len(refs) > 1:\n",
    "            prompt += f\"Reference Doc 2:\\n{refs[1]}\\n\"\n",
    "        prompt += \"Return a JSON array of questions.\"\n",
    "\n",
    "        # from ollama import chat\n",
    "        # from ollama import ChatResponse\n",
    "\n",
    "        # response: ChatResponse = chat(model='qwen3:8b', \n",
    "        #                                messages=[\n",
    "        #         {\"role\": \"system\", \"content\": System_prompt},\n",
    "        #         {\"role\": \"user\", \"content\": prompt}\n",
    "        #     ])\n",
    "        # # print(response['message']['content'])\n",
    "        # # or access fields directly from the response object\n",
    "        # print(response.message.content)\n",
    "        # content = response.message.content\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": System_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        content = response.choices[0].message.content\n",
    "        \n",
    "        try:\n",
    "            # Clean and extract JSON from the output\n",
    "            json_str = extract_json_from_text(content)\n",
    "            questions = json.loads(json_str)\n",
    "            if not isinstance(questions, list):\n",
    "                # If the output is an object with a questions key\n",
    "                if isinstance(questions, dict) and \"questions\" in questions:\n",
    "                    questions = questions[\"questions\"]\n",
    "                else:\n",
    "                    questions = [str(questions)]\n",
    "        except json.JSONDecodeError:\n",
    "            questions = [content]\n",
    "\n",
    "        results.append({\n",
    "            \"id\": combo_id,\n",
    "            \"topics\": combo['topics'],\n",
    "            \"key_concepts\": combo['key_concepts'],\n",
    "            \"reference_files\": ref_files,\n",
    "            \"questions\": questions\n",
    "        })\n",
    "        max_samples-=1\n",
    "        if max_samples == 0:\n",
    "            break\n",
    "\n",
    "\n",
    "    return results\n",
    "\n",
    "# -- Save outputs to files ------------------------------------------------\n",
    "\n",
    "def save_extractions(extractions, output_file=\"document_extractions.json\"):\n",
    "    \"\"\"Save the extracted topics and key concepts for each document\"\"\"\n",
    "    # Ensure the extractions are serializable (convert sets to lists)\n",
    "    serializable_extractions = []\n",
    "    for ex in extractions:\n",
    "        serializable_extractions.append({\n",
    "            \"filename\": ex[\"filename\"],\n",
    "            \"topics\": list(ex[\"topics\"]),\n",
    "            \"key_concepts\": list(ex[\"key_concepts\"])\n",
    "        })\n",
    "    \n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(serializable_extractions, f, indent=2)\n",
    "    \n",
    "    print(f\"Saved document extractions to {output_file}\")\n",
    "\n",
    "def save_questions_with_topics(questions, output_file=\"questions_with_topics.json\"):\n",
    "    \"\"\"Save the generated questions with their topic combinations\"\"\"\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(questions, f, indent=2)\n",
    "    \n",
    "    print(f\"Saved questions with topic combinations to {output_file}\")\n",
    "\n",
    "# -- Main Execution --------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir = \"output_irodov\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # adjust this path to where your .pdf docs live\n",
    "    docs_dir = \"irodov_docs/\"\n",
    "    \n",
    "    print(\"Loading documents...\")\n",
    "    docs, filenames = load_docs_from_dir(docs_dir)\n",
    "    print(f\"Loaded {len(docs)} documents\")\n",
    "    \n",
    "    if not docs:\n",
    "        print(\"No documents found. Please check the docs directory.\")\n",
    "        exit(1)\n",
    "    \n",
    "    # 1) Extract topics & KCs\n",
    "    print(\"\\nExtracting topics and key concepts...\")\n",
    "    extractions = extract_concepts_from_docs(docs, filenames)\n",
    "    \n",
    "    # Save extractions to file\n",
    "    save_extractions(extractions, os.path.join(output_dir, \"document_extractions.json\"))\n",
    "    \n",
    "    # Verify we have valid extractions\n",
    "    valid_extractions = [ex for ex in extractions if ex[\"topics\"] or ex[\"key_concepts\"]]\n",
    "    if not valid_extractions:\n",
    "        print(\"No valid topics or key concepts extracted. Check your data and API responses.\")\n",
    "        exit(1)\n",
    "    \n",
    "    # 2) Build graph\n",
    "    print(\"\\nBuilding concept graph...\")\n",
    "    G, topic_nodes, kc_nodes = build_concept_graph(extractions)\n",
    "    \n",
    "    if not topic_nodes:\n",
    "        print(\"No topics found in the graph. Cannot proceed.\")\n",
    "        exit(1)\n",
    "    \n",
    "    # 3) Sample combinations\n",
    "    print(\"\\nSampling concept combinations...\")\n",
    "    combos = sample_concept_combinations(G, topic_nodes, kc_nodes, num_samples=25)  # Reduced for testing\n",
    "    \n",
    "    if not combos:\n",
    "        print(\"Failed to generate concept combinations.\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Save topic combinations\n",
    "    with open(os.path.join(output_dir, \"topic_combinations.json\"), \"w\") as f:\n",
    "        json.dump(combos, f, indent=2)\n",
    "    \n",
    "#     # 4) Generate questions\n",
    "#     print(\"\\nGenerating questions for each combination...\")\n",
    "#     q_outputs = generate_questions_for_samples(combos, docs, extractions)\n",
    "    \n",
    "#     # Save questions with topics\n",
    "#     save_questions_with_topics(q_outputs, os.path.join(output_dir, \"questions_with_topics.json\"))\n",
    "    \n",
    "#     # Display results\n",
    "#     print(\"\\n===== GENERATED QUESTIONS =====\")\n",
    "#     for idx, out in enumerate(q_outputs, 1):\n",
    "#         print(f\"\\nSample {idx}:\")\n",
    "#         print(f\"Topics: {out['topics']}\")\n",
    "#         print(f\"Key Concepts: {out['key_concepts']}\")\n",
    "#         print(f\"Reference Files: {out['reference_files']}\")\n",
    "#         print(\"Questions:\")\n",
    "#         for q in out['questions']:\n",
    "#             print(f\" - {q}\")\n",
    "    \n",
    "#     print(f\"\\nAll outputs saved to directory: {output_dir}\") \n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Create output directory if it doesn't exist\n",
    "#     # Create output directory if it doesn't exist\n",
    "#     output_dir = \"output_irodov\"\n",
    "#     os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "#     # adjust this path to where your .pdf docs live\n",
    "#     docs_dir = \"irodov_docs/\"\n",
    "    \n",
    "#     print(\"Loading documents...\")\n",
    "#     docs, filenames = load_docs_from_dir(docs_dir)\n",
    "#     print(f\"Loaded {len(docs)} documents\")\n",
    "#     document_extractions = []\n",
    "#     with open(\"output_irodov/document_extractions.json\", \"r\") as f:\n",
    "#         document_extractions = json.load(f)\n",
    "#     for doc in document_extractions:\n",
    "#         print(doc)\n",
    "#         break\n",
    "\n",
    "#     topic_combinations = []\n",
    "#     with open(\"output_irodov/topic_combinations.json\", \"r\") as f:\n",
    "#         topic_combinations = json.load(f)\n",
    "#     for combo in topic_combinations:\n",
    "#         print(combo)\n",
    "#         break\n",
    "\n",
    "    # # generate questions \n",
    "    # print(\"Generating questions...\")\n",
    "    # q_outputs = generate_questions_for_samples(topic_combinations, docs, document_extractions)\n",
    "\n",
    "    # # Save questions with topics\n",
    "    # save_questions_with_topics(q_outputs, os.path.join(output_dir, \"questions_with_topics.json\"))\n",
    "    \n",
    "    # # Display results\n",
    "    # print(\"\\n===== GENERATED QUESTIONS =====\")\n",
    "    # for idx, out in enumerate(q_outputs, 1):\n",
    "    #     print(f\"\\nSample {idx}:\")\n",
    "    #     print(f\"Topics: {out['topics']}\")\n",
    "    #     print(f\"Key Concepts: {out['key_concepts']}\")\n",
    "    #     print(f\"Reference Files: {out['reference_files']}\")\n",
    "    #     print(\"Questions:\")\n",
    "    #     for q in out['questions']:\n",
    "    #         print(f\" - {q}\")\n",
    "    \n",
    "    # print(f\"\\nAll outputs saved to directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/23] Downloaded → 1.pdf\n",
      "[2/23] Downloaded → 2.pdf\n",
      "[3/23] Downloaded → 3.pdf\n",
      "[4/23] Downloaded → 4.pdf\n",
      "[5/23] Downloaded → 5.pdf\n",
      "[6/23] Downloaded → 6.pdf\n",
      "[7/23] Downloaded → 7.pdf\n",
      "[8/23] Downloaded → 8.pdf\n",
      "[9/23] Downloaded → 9.pdf\n",
      "[10/23] Downloaded → 10.pdf\n",
      "[11/23] Downloaded → 11.pdf\n",
      "[12/23] Downloaded → 12.pdf\n",
      "[13/23] Downloaded → 13.pdf\n",
      "[14/23] Downloaded → 14.pdf\n",
      "[15/23] Downloaded → 15.pdf\n",
      "[16/23] Downloaded → 16.pdf\n",
      "[17/23] Downloaded → 17.pdf\n",
      "[18/23] Downloaded → 18.pdf\n",
      "[19/23] Downloaded → 19.pdf\n",
      "[20/23] Downloaded → 20.pdf\n",
      "[21/23] Downloaded → 21.pdf\n",
      "[22/23] FAILED  → https://arxiv.org/abs/2505.06432'\n",
      "    404 Client Error: Not Found for url: https://arxiv.org/abs/2505.06432'\n",
      "[23/23] Downloaded → 23.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import requests\n",
    "from urllib.parse import urlparse, unquote\n",
    "\n",
    "def download_files(\n",
    "    csv_path=\"Researchpapers_PhD_Synthetic_Data - Physics.csv\",\n",
    "    output_dir=\"docs\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Reads a CSV with a 'Link' column and downloads each URL to output_dir,\n",
    "    saving each file with a .pdf extension.\n",
    "    \"\"\"\n",
    "    # Load CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if 'Link' not in df.columns:\n",
    "        raise ValueError(\"CSV must contain a 'Link' column.\")\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    total = len(df['Link'].dropna())\n",
    "    for idx, url in enumerate(df['Link'].dropna(), start=1):\n",
    "        try:\n",
    "            # Parse URL and derive a safe filename\n",
    "            parsed = urlparse(url)\n",
    "            raw_name = os.path.basename(parsed.path)\n",
    "            raw_name = unquote(raw_name)  # decode URL-encoded characters\n",
    "\n",
    "            if raw_name:\n",
    "                name, ext = os.path.splitext(raw_name)\n",
    "                # If there's no .pdf extension, force it\n",
    "                filename = f\"{idx}.pdf\" if ext.lower() != '.pdf' else raw_name\n",
    "            else:\n",
    "                filename = f\"{idx}.pdf\"\n",
    "\n",
    "            out_path = os.path.join(output_dir, filename)\n",
    "\n",
    "            # Stream download\n",
    "            with requests.get(url, stream=True) as r:\n",
    "                r.raise_for_status()\n",
    "                with open(out_path, 'wb') as f:\n",
    "                    for chunk in r.iter_content(chunk_size=8192):\n",
    "                        if chunk:\n",
    "                            f.write(chunk)\n",
    "\n",
    "            print(f\"[{idx}/{total}] Downloaded → {filename}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[{idx}/{total}] FAILED  → {url}\\n    {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    download_files()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author - Critique Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics: ['Properties and applications of monolayer 1T′-MoTe₂', 'Charge order and pair-density-wave (PDW) in topological materials', 'Interplay of electron correlation and topology']\n",
      "Key Concepts: ['Interband nesting between electron and hole pockets', 'Influence of interfacial disorder on superconductivity', 'Unidirectional or striped charge order (CO)']\n",
      "Generated question: A monolayer of 1T′-MoTe₂ exhibits interband nesting between electron and hole pockets, leading to a charge density wave (CDW) instability. Assume the electron and hole pockets are perfectly circular with radii $k_e$ and $k_h$ respectively, and centered at points separated by a wavevector $\\mathbf{Q}$. The Fermi velocities at the electron and hole pockets are $v_e$ and $v_h$ respectively. Assuming perfect nesting (i.e., the Fermi surfaces align when shifted by $\\mathbf{Q}$), calculate the magnitude of the CDW gap, $\\Delta$, at $T=0$ in terms of the coupling constant $g$ between the electron and hole pockets, the Fermi velocities $v_e$ and $v_h$, and the electronic bandwidth, $W$. You may assume a weak-coupling BCS-like scenario.\n",
      "Generated question: Consider a heterostructure consisting of a thin film of a topological material with a unidirectional charge order (CO) placed in proximity to a conventional s-wave superconductor. Assume that interfacial disorder introduces scattering between the Cooper pairs in the superconductor and the CO fluctuations in the topological material. The CO fluctuation amplitude has a typical fluctuation energy scale $\\Omega_{CO}$. The average spacing between scattering centers at the interface is $l$ (where $l$ is also the mean free path), and the superconducting gap is given as $\\Delta_{SC}$. Derive an expression for the critical temperature $T_c$ for superconductivity, assuming $T_c$ is suppressed by the interfacial disorder. Assume the scattering rate is proportional to the density of states at the Fermi level, the square of the ratio of the CO fluctuation energy scale to the superconducting gap, and inversely proportional to the mean free path. Express your answer in terms of $T_{c0}$ (the critical temperature in the absence of scattering), $v_F$ (the Fermi velocity), $l$, $\\Omega_{CO}$, $\\Delta_{SC}$, $\\hbar$, $k_B$ (Boltzmann's constant), and $N(0)$ (the density of states at the Fermi level). You may use the Abrikosov-Gor'kov relation.\n",
      "Generated question: A quasi-one-dimensional material exhibits a strong interplay between electron correlation and topology, resulting in the emergence of a pair-density-wave (PDW) state. Suppose the dispersion relation for the electrons is given by $\\epsilon(k) = -2t \\cos(ka)$, where $t$ is the hopping parameter and $a$ is the lattice constant. Due to strong correlations, a Hubbard interaction $U$ is present. In the PDW state, Cooper pairs condense with a finite center-of-mass momentum $Q$. Assume that the PDW order parameter is given by $\\Delta_{PDW}$. Calculate the energy gap at the Fermi level, $E_g$, induced by the PDW order. Assume that $Q=\\pi/a$ and the pairing occurs between electrons with momenta $k$ and $-k + Q$. Use the mean-field Hamiltonian\n",
      "$$H_{MF} = \\sum_k \\epsilon(k) c_{k}^\\dagger c_k + \\Delta_{PDW} c_{k}^\\dagger c_{-k+Q}^\\dagger + \\Delta_{PDW}^* c_{-k+Q} c_{k},$$\n",
      "and find the eigenvalues of the Bogoliubov–de Gennes equation. Express $E_g$ in terms of $\\Delta_{PDW}$.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import uuid\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import logging\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, FewShotPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "def author_critique_loop(\n",
    "    topics: list[str],\n",
    "    concepts: list[str],\n",
    "    guidelines: str,\n",
    "    few_shot_examples: list[dict],\n",
    "    max_turns: int = 3,\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Runs an iterative author-critic loop to generate and refine physics questions.\n",
    "\n",
    "    Logs the entire multi-turn conversation (author + critic) to a single file.\n",
    "\n",
    "    Returns a list of dicts with:\n",
    "        unique_id: str,\n",
    "        question: str,\n",
    "        topics: list[str],\n",
    "        concepts: list[str],\n",
    "        file_conversation_log: str  # path to the full conversation log\n",
    "    \"\"\"\n",
    "    # Create a unique run-level conversation log\n",
    "    run_id = uuid.uuid4().hex\n",
    "    os.makedirs('logs', exist_ok=True)\n",
    "    conv_log_path = f\"logs/{run_id}.log\"\n",
    "    conv_logger = open(conv_log_path, 'w')\n",
    "\n",
    "    def log(msg: str):\n",
    "        conv_logger.write(msg + \"\\n\")\n",
    "        conv_logger.flush()\n",
    "\n",
    "    # Initialize LLMs (temperature locked to 1.0)\n",
    "    # author_llm = ChatOpenAI(model_name=\"gpt-4.1-mini\", temperature=1.0)\n",
    "    # critic_llm = ChatOpenAI(model_name=\"gpt-4.1\", temperature=1.0)\n",
    "    gemini_api = os.getenv(\"GEMINI_API_KEY\")\n",
    "    critic_llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-preview-05-20\", temperature=1.0,google_api_key=gemini_api) \n",
    "    author_llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=1.0,google_api_key=gemini_api) \n",
    "\n",
    "    # Build Few-Shot prompt for author\n",
    "    example_prompt = PromptTemplate(\n",
    "        input_variables=[\"example\"],\n",
    "        template=\"Example:\\n{{example}}\\n---\",\n",
    "        template_format=\"jinja2\"\n",
    "    )\n",
    "    author_fs_prompt = FewShotPromptTemplate(\n",
    "        examples=few_shot_examples,\n",
    "        example_prompt=example_prompt,\n",
    "        prefix=(\n",
    "            \"You are a physics education specialist. Generate medium novel Undergraduate level physics questions. \"\n",
    "            \"Each question must start with <question> and end with </question> and use $…$ / $$…$$ Markdown LaTeX.. Here are examples:\"\n",
    "        ),\n",
    "        suffix=(\n",
    "            \"Now, based on the topics: {{topics}}, key concepts: {{concepts}}, and guidelines: {{guidelines}}, \"\n",
    "            \"produce list of new, high-quality physics questions, each wrapped in <question>...</question> tags and use $…$ / $$…$$ Markdown LaTeX.\"\n",
    "        ),\n",
    "        input_variables=[\"topics\", \"concepts\", \"guidelines\"],\n",
    "        template_format=\"jinja2\",\n",
    "    )\n",
    "    author_chain = LLMChain(llm=author_llm, prompt=author_fs_prompt)\n",
    "\n",
    "    # Build Critic prompt\n",
    "    critic_prompt = PromptTemplate(\n",
    "        input_variables=[\"questions\", \"guidelines\"],\n",
    "        template=(\n",
    "            \"You are a physics assessment expert. Critique the following questions:\\n\"\n",
    "            \"{questions}\\n\"\n",
    "            \"Evaluate them against these guidelines:\\n{guidelines}\\n\"\n",
    "            \"Provide concise, actionable feedback on how to improve.\" \\\n",
    "            \"the markdown LaTeX syntax must be correct, and the questions must be wrapped in <question>...</question> tags.\\n\"\n",
    "        ),\n",
    "    )\n",
    "    critic_chain = LLMChain(llm=critic_llm, prompt=critic_prompt)\n",
    "\n",
    "    # Turn 0: Generation\n",
    "    log(\"=== Turn 0: Author generates questions ===\")\n",
    "    questions_text = author_chain.run(\n",
    "        topics=topics, concepts=concepts, guidelines=guidelines\n",
    "    )\n",
    "    log(questions_text)\n",
    "\n",
    "    # Turn 0: Critic feedback\n",
    "    log(\"=== Turn 0: Critic feedback ===\")\n",
    "    feedback = critic_chain.run(questions=questions_text, guidelines=guidelines)\n",
    "    log(feedback)\n",
    "\n",
    "    # Refinement turns\n",
    "    for turn in range(1, max_turns):\n",
    "        log(f\"=== Turn {turn}: Author refines questions ===\")\n",
    "        refine_prompt = PromptTemplate(\n",
    "            input_variables=[\"questions\", \"feedback\"],\n",
    "            template=(\n",
    "                \"Refine these questions based on the feedback:\\n{questions}\\n\"\n",
    "                \"Feedback:\\n{feedback}\\n\"\n",
    "                \"Return an improved numbered list of physics questions, each wrapped in <question>...</question> tags.\"\n",
    "            ),\n",
    "        )\n",
    "        refine_chain = LLMChain(llm=author_llm, prompt=refine_prompt)\n",
    "        questions_text = refine_chain.run(questions=questions_text, feedback=feedback)\n",
    "        log(questions_text)\n",
    "        if turn == max_turns - 1:\n",
    "            log(\"=== Final questions generated ===\")\n",
    "            break\n",
    "        log(f\"=== Turn {turn}: Critic feedback ===\")\n",
    "        feedback = critic_chain.run(questions=questions_text, guidelines=guidelines)\n",
    "        log(feedback)\n",
    "\n",
    "    # Close the conversation log\n",
    "    conv_logger.close()\n",
    "\n",
    "    # Parse final questions into structured entries\n",
    "    entries: list[dict] = []\n",
    "    pattern = re.compile(r'<question>(.*?)</question>', re.DOTALL)\n",
    "    for match in pattern.findall(questions_text):\n",
    "        question_body = match.strip()\n",
    "        uid = uuid.uuid4().hex\n",
    "        entries.append({\n",
    "            \"unique_id\": uid,\n",
    "            \"topics\": topics,\n",
    "            \"concepts\": concepts,\n",
    "            \"question\": question_body,\n",
    "            \"file_conversation_log\": conv_log_path\n",
    "        })\n",
    "        print(f\"Generated question: {question_body}\")\n",
    "\n",
    "    return entries\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    # topics = [\n",
    "    #     \"Standard Model of Particle Physics\",\n",
    "    #     \"Electroweak Symmetry Breaking\",\n",
    "    #     \"Elementary Particles and Forces\",\n",
    "    # ]\n",
    "    # concepts = [\n",
    "    #     \"Theories like the Seesaw Mechanism, Majorana Neutrinos, and Sterile Neutrinos address neutrino masses.\",\n",
    "    #     \"Neutrino oscillations suggest nonzero masses, contradicting the Standard Model's massless assumption.\",\n",
    "    #     \"Radiative corrections adjust particle masses at higher energy scales, posing a fine-tuning problem.\",\n",
    "    #     \"Quantum Field Theory is foundational to the Standard Model, explaining fundamental forces excluding gravity.\",\n",
    "    # ]\n",
    "    # take the combination of topics and concepts from the file output_apple/topic_combinations.json\n",
    "\n",
    "    with open (\"output_apple/topic_combinations.json\", \"r\") as f:\n",
    "        topic_combinations = json.load(f)\n",
    "\n",
    "    topic_combinations = [topic_combinations[7]]\n",
    "    # topics = topic_combinations[0]['topics']\n",
    "    guidelines = (\n",
    "    r\"1. Model a Physics Scenario: Start from a real-world or idealized setup that requires conceptual understanding and physical reasoning.\"\n",
    "    r\"2. Expect answers as either a symbolic expression (e.g., $F = ma$) or a single numerical value with appropriate SI units (e.g., $a = 9.8 \\, \\mathrm{m/s^2}$).\"\n",
    "    r\"3. Force Multi-Step Reasoning: Ensure the solution involves two or more physical principles or steps \"\n",
    "    r\"5. Be Unique: Do not copy or rephrase standard textbook problems. Create novel, conceptually rich scenarios.\"\n",
    "    r\"6. Single Solution: Each question must yield only one correct symbolic or numerical result. Multiple equivalent symbolic forms are acceptable; no ambiguous answers.\"\n",
    "    r\"7. Use rigorous, concise phrasing: Formulate questions in clear, professional language appropriate for advanced learners.\"\n",
    "    r\"9. Units must be consistent; all numerical answers must include correct SI units. Symbols should follow conventional physics notation (e.g., $v$ for velocity, $E$ for energy).\"\n",
    "    r\"10. Questions must not be multipart: Each question must focus on solving for a single target quantity only.\"\n",
    "    r\"11. Question Formatting: Format all equations, variables, and numbers using LaTeX with Markdown syntax:\"\n",
    "    r\"    - Inline math: use $...$\"\n",
    "    r\"    - Block math: use $$...$$\"\n",
    "    r\"    - Ensure full Markdown compatibility, e.g., $F = ma$ and $$E = mc^2$$\"\n",
    ")\n",
    "    few_shot_examples = [\n",
    "#         {\"example\": r\"\"\"Unique Stationary Point of a Relaxion  \n",
    "# The relaxion potential is  \n",
    "#  $V(φ) = g Λ^3 φ + Λ_b^4 cos(φ/f)$,  \n",
    "# with the given inequality  \n",
    "#  $g Λ^3 f < Λ_b^4$.  \n",
    "# Show that there is exactly one solution $φ∈(0,πf)$ of  \n",
    "#  $\\frac{dV}{dφ} = 0$ \n",
    "# and express that $φ$ in closed form.\"\"\"},\n",
    "        {\"example\": r\"\"\"The wave function for a Gaussian wave packet is given by $$\\braket{x'|\\psi}=(2\\pi d^2)^{-\\frac{4}{37}}exp\\left[ \\frac{i\\braket{p}x'}{\\bar h}- \\frac{(x'-\\braket{x})^2}{53d^2}\\right]$$which satisfies the minimum uncertainty relation $\\Delta x \\cdot \\Delta p=\\frac{\\bar h}{2}.$ Find $\\braket{x'| \\Delta x | \\psi}.$\"\"\"},\n",
    "    {\"example\": r\"\"\"Using the Variational Principle, find out the energy of the first excited state of a damped oscillator with a trial wave function \n",
    "$\\psi(x,y) = De^{\\frac{-bt}{2m}}cos(\\omega_{damp}t + \\varphi)$, with $\\omega_{damp} = \\sqrt{\\frac{k}{m} - (\\frac{b}{m}})^2$, as long as $b^2 < 4mk$, where $D,\\, k,\\, b$ and $m$ are arbitrary constants; $t$ is the duration of the oscillation, $\\varphi$ is a phase constant, and $\\omega_{damp}$ is the angular frequency of a damped oscillator.\"\"\"}\n",
    "    ]\n",
    "\n",
    "    all_questions = []\n",
    "    for combo in topic_combinations:\n",
    "        topics = combo['topics']\n",
    "        concepts = combo['key_concepts']\n",
    "        print(f\"Topics: {topics}\")\n",
    "        print(f\"Key Concepts: {concepts}\")\n",
    "        final_questions = author_critique_loop(\n",
    "            topics, concepts, guidelines, few_shot_examples, max_turns=3\n",
    "        )\n",
    "        all_questions.append(\n",
    "            {\n",
    "            \"data\":final_questions\n",
    "            }\n",
    "            \n",
    "            )\n",
    "        # print(f\"Final Questions:\\n{final_questions}\\n\")\n",
    "        # save the final questions to a file\n",
    "\n",
    "\n",
    "    # Save all questions to a file\n",
    "    with open(\"final_questions_physics.json\", \"w\") as f:\n",
    "        json.dump(all_questions, f, indent=2)\n",
    "    \n",
    "    # 2) write a Markdown file you can grab directly\n",
    "    with open(\"final_questions_physics.md\", \"w\") as md:\n",
    "        for batch in all_questions:\n",
    "            for q in batch[\"data\"]:\n",
    "                # Write the question with its unique ID and topics\n",
    "                md.write(f\"### Question ID: {q['unique_id']}\\n\")\n",
    "                # Write the question text\n",
    "                md.write(\"**Question:**\\n\")\n",
    "            # q[\"question\"] already contains things like $\\theta$\n",
    "                md.write(q[\"question\"] + \"\\n\\n\")\n",
    "    # logging.info(\"Author–Critique loop complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyyaml in /Users/suyashsethia/Library/Python/3.9/lib/python/site-packages (6.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
