{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9 documents\n",
      "\n",
      "Extracting topics and key concepts...\n",
      "Raw output: ```json\n",
      "{\n",
      "  \"topics\": [\n",
      "    \"Iron-catalyzed hydroamidation\",\n",
      "    \"C–N bond formation\",\n",
      "    \"Radical hydrofunctionalization\",\n",
      "    \"15N-labelling of compounds\",\n",
      "    \"Catalysis in organic synthesis\"\n",
      "  ],\n",
      "  \"key_concepts\": [\n",
      "    \"Iron-catalysed radical Markovnikov hydroamidation\",\n",
      "    \"Complex alkene substrates\",\n",
      "    \"Nitrogen atom importance\",\n",
      "    \"Transition-metal-catalysed synthesis\",\n",
      "    \"Synthetic methodologies for C-N bond formation\",\n",
      "    \"Alkyl radical amidation reagent design\",\n",
      "    \"C–N cross coupling and hydroamination\",\n",
      "    \"Markovnikov and anti-Markovnikov products\",\n",
      "    \"Diastereoselective synthesis\",\n",
      "    \"Cyanamide functionality\",\n",
      "    \"Application in pharmaceuticals and agrochemicals\",\n",
      "    \"15N-labelled amine synthesis\",\n",
      "    \"Transition-metal catalysis benefits\",\n",
      "    \"Mechanistic studies in hydroamidation\",\n",
      "    \"Functional group tolerance in reactions\",\n",
      "    \"Late-stage modification of natural products\",\n",
      "    \"Stereoselective reactions in chemistry\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "Successfully extracted 5 topics and 17 key concepts from s44160-025-00792-w.pdf\n",
      "Raw output: ```json\n",
      "{\n",
      "  \"topics\": [\n",
      "    \"Glycosylation Chemistry\",\n",
      "    \"Cryogenic Infrared Spectroscopy\",\n",
      "    \"Glycosyl Cation Structure\",\n",
      "    \"Carbohydrate Synthesis\",\n",
      "    \"Reaction Mechanisms\",\n",
      "    \"Computational Chemistry\",\n",
      "    \"Stereoselectivity in Glycosylation\"\n",
      "  ],\n",
      "  \"key_concepts\": [\n",
      "    \"1,2-Cis Glycosidic Linkages\",\n",
      "    \"4,6-O-Benzylidene Protection\",\n",
      "    \"Covalent and Cationic Intermediates\",\n",
      "    \"S1 vs SN2 Glycosylation Mechanisms\",\n",
      "    \"Anhydro Cation Formation\",\n",
      "    \"Gas-Phase vs Solution-Phase Structures\",\n",
      "    \"Charge Delocalization in Glycosyl Cations\",\n",
      "    \"Temperature and Solvent Effects on Reaction Mechanism\",\n",
      "    \"Stereoselectivity Determined by Intermediate Structure\",\n",
      "    \"Density Functional Theory (DFT) for Structural Analysis\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "Successfully extracted 7 topics and 10 key concepts from s44160-024-00619-0.pdf\n",
      "Raw output: ```json\n",
      "{\n",
      "  \"topics\": [\n",
      "    \"Iron-catalysis\",\n",
      "    \"Organosodium compounds\",\n",
      "    \"Sustainable chemistry\",\n",
      "    \"Organic synthesis\",\n",
      "    \"Transition metal catalysis\"\n",
      "  ],\n",
      "  \"key_concepts\": [\n",
      "    \"Iron-catalysed direct coupling\",\n",
      "    \"C(sp2)–C(sp2) oxidative homocoupling\",\n",
      "    \"C(sp2)–C(sp3) cross-coupling\",\n",
      "    \"Mechanistic investigations using organoiron intermediates\",\n",
      "    \"Use of bidentate additives for catalytic reactivity control\",\n",
      "    \"Sodium as an abundant and non-toxic alternative to lithium\",\n",
      "    \"Applications in synthetic and materials science\",\n",
      "    \"Fe(II) radical mechanisms\",\n",
      "    \"Additives influencing aggregation states of organosodium\",\n",
      "    \"Radical-clock experiments for mechanistic insights\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "Successfully extracted 5 topics and 10 key concepts from s44160-025-00771-1.pdf\n",
      "Raw output: ```json\n",
      "{\n",
      "  \"topics\": [\n",
      "    \"Intracellular supramolecular assembly\",\n",
      "    \"Peptide nanostructures\",\n",
      "    \"Photochemical control in living cells\",\n",
      "    \"Real-time visualization of assembly processes\",\n",
      "    \"Synthetic chemistry in cellular environments\"\n",
      "  ],\n",
      "  \"key_concepts\": [\n",
      "    \"Photocaged pro-assembling peptides\",\n",
      "    \"Visible light-induced transformations\",\n",
      "    \"Phasor-fluorescence lifetime imaging\",\n",
      "    \"Cellular uptake and internalization\",\n",
      "    \"Photocleavable protecting groups\",\n",
      "    \"Control of assembly kinetics via light\",\n",
      "    \"Correlation of supramolecular phases with cytotoxicity\",\n",
      "    \"Co-assembly and nanostructure formation\",\n",
      "    \"Dynamics of monomer and oligomer formation\",\n",
      "    \"NIR-fluorophore tracking of assemblies\",\n",
      "    \"Properties of optoaggregates and nanofibres\",\n",
      "    \"Impact of assembly on cell viability\",\n",
      "    \"Endosomal escape and intracellular environments\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "Successfully extracted 5 topics and 13 key concepts from s44160-025-00751-5.pdf\n",
      "Raw output: ```json\n",
      "{\n",
      "  \"topics\": [\n",
      "    \"Covalent Organic Frameworks (COFs)\",\n",
      "    \"Photocatalysis\",\n",
      "    \"Hydrogen Peroxide Production\",\n",
      "    \"Near-Infrared Light Harvesting\",\n",
      "    \"Cyclopalladation\",\n",
      "    \"Materials Science\",\n",
      "    \"Energy Conversion\"\n",
      "  ],\n",
      "  \"key_concepts\": [\n",
      "    \"Post-synthetic Functionalization\",\n",
      "    \"Light Absorption in NIR Region\",\n",
      "    \"Photocatalytic Oxygen Reduction\",\n",
      "    \"Palladium-Functionalized COFs\",\n",
      "    \"Atomically Distributed Palladium\",\n",
      "    \"Gas Storage and Separation\",\n",
      "    \"Crystallinity and Structural Stability\",\n",
      "    \"Charge Recombination Mitigation\",\n",
      "    \"Photocatalytic Efficiency Enhancement\",\n",
      "    \"Mechanism of Hydrogen Peroxide Formation\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "Successfully extracted 7 topics and 10 key concepts from s44160-024-00731-1.pdf\n",
      "Raw output: ```json\n",
      "{\n",
      "  \"topics\": [\n",
      "    \"Wiley Online Library\",\n",
      "    \"Open Access (OA)\",\n",
      "    \"Creative Commons License\",\n",
      "    \"Terms and Conditions\"\n",
      "  ],\n",
      "  \"key_concepts\": [\n",
      "    \"Rules of use\",\n",
      "    \"OA articles governance\",\n",
      "    \"Creative Commons applicable license\",\n",
      "    \"Advanced Portfolio access\",\n",
      "    \"Usage terms on Wiley\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "Successfully extracted 4 topics and 5 key concepts from Radical Cross Coupling and Enantioselective Protonation through Asymmetric Photoredox Catalysis.pdf\n",
      "Raw output: ```json\n",
      "{\n",
      "  \"topics\": [\n",
      "    \"Organic Synthesis\",\n",
      "    \"Halogenation Chemistry\",\n",
      "    \"Nucleophile–Nucleophile Reactions\"\n",
      "  ],\n",
      "  \"key_concepts\": [\n",
      "    \"Selective Hetero-Dihalogenation\",\n",
      "    \"Diastereodivergent Chlorofluorination\",\n",
      "    \"Mechanistic Studies\",\n",
      "    \"Regio- and Chemoselectivity\",\n",
      "    \"Hypervalent Iodine Compounds\",\n",
      "    \"Syn- and Anti-Addition Pathways\",\n",
      "    \"Electrochemical Methods\",\n",
      "    \"Organic Fluorination\",\n",
      "    \"Reaction Solvent Composition\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "Successfully extracted 3 topics and 9 key concepts from s41557-024-01561-6 (1).pdf\n",
      "Raw output: ```json\n",
      "{\n",
      "  \"topics\": [\n",
      "    \"Heterobimetallic Dimetallocene Chemistry\",\n",
      "    \"Synthetic Chemistry\",\n",
      "    \"Organometallic Chemistry\",\n",
      "    \"Bonding Theory\",\n",
      "    \"Reactivity Studies\"\n",
      "  ],\n",
      "  \"key_concepts\": [\n",
      "    \"Heterobimetallic Dimetallocene: Synthesis and characterization of lithium–aluminium heterobimetallic dimetallocene with unique Al–Li bond properties.\",\n",
      "    \"Monomeric Cyclopentadienylaluminylene: Isolation and structural characterization of monomeric cyclopentadienylaluminylene, which is key to the synthesis of heterobimetallic dimetallocene.\",\n",
      "    \"Al–Li Bond Characteristics: The Al–Li bond shows a high ionic character supported by attractive dispersion interactions, differentiating it from other metal-metal bonds.\",\n",
      "    \"Reactivity with N-Heterocyclic Carbenes: The Al–Li bond in the dimetallocene is cleaved by N-heterocyclic carbenes, leading to new organometallic structures.\",\n",
      "    \"Comparison with Dizincocene and Diberyllocene: Unlike dizincocene and diberyllocene, the Al–Li bond in lithium–aluminium dimetallocene is reinforced by dispersion interactions and not by strong electron-sharing.\",\n",
      "    \"Use of Pentaisopropylcyclopentadienyl Ligands: These ligands play a critical role in stabilizing the Al–Li bond through steric and dispersion interactions.\",\n",
      "    \"Energy Decomposition Analysis (EDA): Provides insight into the electronic structure of the heterobimetallic dimetallocene, emphasizing the role of dispersion interactions.\",\n",
      "    \"Crystal Structure and NMR Characterization: Single-crystal X-ray diffraction and multinuclear NMR spectroscopy are used to determine structures and study the bonding configurations.\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "Successfully extracted 5 topics and 8 key concepts from s41557-024-01531-y.pdf\n",
      "Raw output: ```json\n",
      "{\n",
      "    \"topics\": [\n",
      "        \"Difunctionalization of Bicyclo[1.1.0]butanes\",\n",
      "        \"Ruthenium-catalyzed Chemistry\",\n",
      "        \"Medicinal Chemistry\",\n",
      "        \"Synthetic Chemistry\",\n",
      "        \"Mechanistic Studies in Chemistry\",\n",
      "        \"Catalysis\",\n",
      "        \"Strain-release Reactions\"\n",
      "    ],\n",
      "    \"key_concepts\": [\n",
      "        \"C–C scission in Bicyclo[1.1.0]butanes (BCBs)\",\n",
      "        \"Ruthenium-catalyzed remote C−H activation\",\n",
      "        \"Synthesis of tri- and tetrasubstituted cyclobutanes\",\n",
      "        \"High sp3-hybridized carbon atom content (Fsp3) in medicinal chemistry\",\n",
      "        \"Ample substrate scope under mild conditions\",\n",
      "        \"Multifunctional ruthenium(II) catalyst for Ru-XAT (ruthenacycle-mediated halogen-atom transfer)\",\n",
      "        \"Chemo-controlled functionalization\",\n",
      "        \"Mechanistic insights from experimental and computational studies\",\n",
      "        \"DFT calculations for reaction site selectivity\",\n",
      "        \"Single-step cyclobutane synthesis\",\n",
      "        \"Phosphine ligand role in catalytic processes\",\n",
      "        \"Innovations in drug design through cyclobutane scaffolds\",\n",
      "        \"Broad substrate tolerance in catalyst-mediated reactions\",\n",
      "        \"Role of strain-release in bond scission and functionalization\"\n",
      "    ]\n",
      "}\n",
      "```\n",
      "Successfully extracted 7 topics and 14 key concepts from s44160-025-00745-3.pdf\n",
      "Saved document extractions to output_chemistry/document_extractions_chemistry.json\n",
      "\n",
      "Building concept graph...\n",
      "Graph built with 47 topics and 96 key concepts\n",
      "\n",
      "Sampling concept combinations...\n",
      "Sampling from 47 topics\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "from collections import Counter\n",
    "import networkx as nx\n",
    "import pdfplumber\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key from environment variable\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# -- Document Loading ------------------------------------------------------\n",
    "\n",
    "def load_docs_from_dir(dir_path):\n",
    "    \"\"\"\n",
    "    Load all .pdf files from a directory and extract their full text.\n",
    "    Returns a list of strings, one per PDF.\n",
    "    \"\"\"\n",
    "    docs = []\n",
    "    filenames = []\n",
    "    for filepath in glob.glob(os.path.join(dir_path, '*.pdf')):\n",
    "        try:\n",
    "            text_pages = []\n",
    "            with pdfplumber.open(filepath) as pdf:\n",
    "                for page in pdf.pages:\n",
    "                    text_pages.append(page.extract_text() or \"\")\n",
    "            full_text = \"\\n\".join(text_pages)\n",
    "            docs.append(full_text)\n",
    "            filenames.append(os.path.basename(filepath))\n",
    "        except Exception as e:\n",
    "            # skip unreadable PDFs\n",
    "            print(f\"Warning: could not load {filepath}: {e}\")\n",
    "    return docs, filenames\n",
    "\n",
    "# -- 1. Extract topics and key concepts -----------------------------------\n",
    "\n",
    "def extract_json_from_text(text):\n",
    "    \"\"\"Helper function to extract JSON content from markdown code blocks or raw text\"\"\"\n",
    "    # Try to extract JSON from markdown code blocks\n",
    "    json_match = re.search(r'```(?:json)?\\s*(.*?)\\s*```', text, re.DOTALL)\n",
    "    if json_match:\n",
    "        return json_match.group(1).strip()\n",
    "    \n",
    "    # If no code blocks, try to find JSON-like structures\n",
    "    json_match = re.search(r'(\\{.*\\})', text, re.DOTALL)\n",
    "    if json_match:\n",
    "        return json_match.group(1).strip()\n",
    "    \n",
    "    # Return original text if no JSON structure found\n",
    "    return text\n",
    "\n",
    "def extract_concepts_from_docs(doc_texts, filenames, model=\"gpt-4o\"):  \n",
    "    \"\"\"\n",
    "    Call OpenAI API to extract topics and key concepts from each document.\n",
    "    Returns list of dicts with keys 'topics' and 'key_concepts'.\n",
    "    \"\"\"\n",
    "    extractions = []\n",
    "    for i, text in enumerate(doc_texts):\n",
    "        filename = filenames[i] if i < len(filenames) else f\"doc_{i}\"\n",
    "        \n",
    "        prompt = (\n",
    "            \"Extract high-level topics and key concepts from the following document. \"\n",
    "            f\"Return JSON with keys 'topics' and 'key_concepts'.\\n\\n{text}\"\n",
    "        )\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert summarizer. Return your response as a JSON object with 'topics' and 'key_concepts' as arrays.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "        )\n",
    "        \n",
    "        output = response.choices[0].message.content\n",
    "        print(\"Raw output:\", output)\n",
    "        \n",
    "        try:\n",
    "            # Clean and extract JSON from the output\n",
    "            json_str = extract_json_from_text(output)\n",
    "            data = json.loads(json_str)\n",
    "            \n",
    "            # Ensure we have the expected keys\n",
    "            if \"topics\" in data and \"key_concepts\" in data:\n",
    "                extraction = {\n",
    "                    \"filename\": filename,\n",
    "                    \"topics\": data[\"topics\"],\n",
    "                    \"key_concepts\": data[\"key_concepts\"]\n",
    "                }\n",
    "                extractions.append(extraction)\n",
    "                print(f\"Successfully extracted {len(data['topics'])} topics and {len(data['key_concepts'])} key concepts from {filename}\")\n",
    "            else:\n",
    "                print(f\"Warning: Parsed JSON doesn't have expected keys: {data.keys()}\")\n",
    "                extractions.append({\n",
    "                    \"filename\": filename,\n",
    "                    \"topics\": [], \n",
    "                    \"key_concepts\": []\n",
    "                })\n",
    "                \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Failed to parse JSON: {e}\")\n",
    "            extractions.append({\n",
    "                \"filename\": filename,\n",
    "                \"topics\": [], \n",
    "                \"key_concepts\": []\n",
    "            })\n",
    "    \n",
    "    return extractions\n",
    "\n",
    "# -- 2. Construct the concept graph ----------------------------------------\n",
    "\n",
    "def build_concept_graph(extractions, eps=1e-6):\n",
    "    \"\"\"\n",
    "    Build a unified graph G where nodes are topics + key concepts and\n",
    "    edges weighted by log(freq+eps) based on co-occurrence in docs.\n",
    "    Returns: G (nx.Graph), topic_nodes, kc_nodes\n",
    "    \"\"\"\n",
    "    freq = Counter()\n",
    "    all_topics, all_kcs = set(), set()\n",
    "\n",
    "    for ex in extractions:\n",
    "        nodes = ex[\"topics\"] + ex[\"key_concepts\"]\n",
    "        for i in range(len(nodes)):\n",
    "            for j in range(i+1, len(nodes)):\n",
    "                u, v = sorted((nodes[i], nodes[j]))\n",
    "                freq[(u, v)] += 1\n",
    "        all_topics.update(ex[\"topics\"])\n",
    "        all_kcs.update(ex[\"key_concepts\"])\n",
    "\n",
    "    G = nx.Graph()\n",
    "    for (u, v), f in freq.items():\n",
    "        weight = math.log(f + eps)\n",
    "        G.add_edge(u, v, weight=weight)\n",
    "\n",
    "    print(f\"Graph built with {len(all_topics)} topics and {len(all_kcs)} key concepts\")\n",
    "    return G, all_topics, all_kcs\n",
    "\n",
    "# -- Helpers for sampling --------------------------------------------------\n",
    "\n",
    "def softmax(weights):\n",
    "    exps = [math.exp(w) for w in weights]\n",
    "    s = sum(exps) or 1.0\n",
    "    return [e/s for e in exps]\n",
    "\n",
    "\n",
    "def random_walk(G, start, steps):\n",
    "    \"\"\"\n",
    "    Random walk on graph G for given steps from 'start',\n",
    "    with transition probabilities via softmax over edge weights.\n",
    "    \"\"\"\n",
    "    path = [start]\n",
    "    current = start\n",
    "    for _ in range(steps):\n",
    "        nbrs = list(G[current])\n",
    "        if not nbrs:\n",
    "            break\n",
    "        weights = [G[current][n]['weight'] for n in nbrs]\n",
    "        probs = softmax(weights)\n",
    "        current = random.choices(nbrs, probs)[0]\n",
    "        path.append(current)\n",
    "    return path\n",
    "\n",
    "# -- 3. Concept combination sampling ---------------------------------------\n",
    "\n",
    "def sample_concept_combinations(\n",
    "    G, topic_nodes, kc_nodes,\n",
    "    num_samples=100,\n",
    "    topic_walk_steps=(1, 2),\n",
    "    kc_walk_steps=(3, 4)\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate sampled sets of topics and key concepts via multi-stage random walks.\n",
    "    Returns list of dicts: {'topics': set, 'key_concepts': set}\n",
    "    \"\"\"\n",
    "    # Safety check\n",
    "    if not topic_nodes:\n",
    "        print(\"Error: No topics found. Cannot sample combinations.\")\n",
    "        return []\n",
    "        \n",
    "    G_topic = G.subgraph(topic_nodes)\n",
    "    G_topic_kc = G.subgraph(topic_nodes | kc_nodes)\n",
    "    G_kc = G.subgraph(kc_nodes)\n",
    "    samples = []\n",
    "\n",
    "    topics_list = list(topic_nodes)\n",
    "    print(f\"Sampling from {len(topics_list)} topics\")\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        t0 = random.choice(topics_list)\n",
    "        t_steps = random.choice(topic_walk_steps)\n",
    "        topic_path = random_walk(G_topic, t0, t_steps)\n",
    "        sampled_topics = set(topic_path)\n",
    "\n",
    "        kc_cands = [nbr for t in sampled_topics for nbr in G_topic_kc[t] if nbr in kc_nodes]\n",
    "        if kc_cands:\n",
    "            k0 = random.choice(kc_cands)\n",
    "            k_steps = random.choice(kc_walk_steps)\n",
    "            kc_path = random_walk(G_kc, k0, k_steps)\n",
    "            sampled_kcs = set(kc_path)\n",
    "        else:\n",
    "            sampled_kcs = set()\n",
    "\n",
    "        samples.append({\n",
    "            \"topics\": list(sampled_topics),  # Convert sets to lists for JSON serialization\n",
    "            \"key_concepts\": list(sampled_kcs)\n",
    "        })\n",
    "    \n",
    "    return samples\n",
    "\n",
    "# -- 4. Question generation ------------------------------------------------\n",
    "\n",
    "def generate_questions_for_samples(combos, docs, extractions, model=\"gpt-4o\"):  \n",
    "    \"\"\"\n",
    "    For each sampled combo, pick two docs via Jaccard on concept sets,\n",
    "    then call LLM to generate questions.\n",
    "    Returns list of dicts: {'sample': combo, 'questions': [...]}.\n",
    "    \"\"\"\n",
    "    doc_concepts = [set(ex['topics'] + ex['key_concepts']) for ex in extractions]\n",
    "    # doc_concepts= doc_concepts[:1]\n",
    "    results = []\n",
    "    max_samples = 100\n",
    "    # combos = combos[:max_samples]\n",
    "    for i, combo in enumerate(combos):\n",
    "        combo_id = f\"combo_{i+1}\"\n",
    "        kg = set(combo['topics']) | set(combo['key_concepts'])\n",
    "        sims = []\n",
    "        for idx, dc in enumerate(doc_concepts):\n",
    "            inter = kg & dc\n",
    "            union = kg | dc\n",
    "            sims.append((len(inter) / (len(union) or 1), idx))\n",
    "        sims.sort(reverse=True)\n",
    "        top_idxs = [i for _, i in sims[:2]]\n",
    "        refs = [docs[i] for i in top_idxs]\n",
    "        ref_files = [extractions[i][\"filename\"] for i in top_idxs]\n",
    "        System_prompt =f\"\"\"\n",
    "Each question must follow these instructions:\n",
    "Model a Chemistry Scenario: Start from a real-world or idealized setup. Avoid abstract chemistry problems or purely conceptual statements.\n",
    "Target a Solvable Quantity: Ask for a clear symbolic expression of a physical variable (e.g., tension, acceleration, energy).\n",
    "Force Multi-Step Reasoning: Ensure the question involves a sequence of chemistry laws, transformations, and derivations to reach the answer.\n",
    "Avoid Redundancy: Exclude extraneous details or variables that do not impact the final solution.\n",
    "Be Unique: Do not rephrase standard textbook problems; ensure originality and complexity.\n",
    "Single solution: Expect a single symbolic expression, unambiguous, presented in LaTeX. Multiple equivalent algebraic forms are allowed. No equations or floating-point approximations.\n",
    "Use rigorous, concise phrasing.\n",
    "Avoid colloquial or ambiguous terminology.\n",
    "Units must be consistent; symbols should follow standard notation.\n",
    "\"\"\"\n",
    "        prompt = (\n",
    "            f\"Generate a set of difficult chemistry questions based on the following:\\n\"\n",
    "            \n",
    "            f\"Topics: {combo['topics']}\\n\"\n",
    "            f\"Key Concepts: {combo['key_concepts']}\\n\"\n",
    "            f\"Reference Doc 1:\\n{refs[0]}\\n\"\n",
    "        )\n",
    "        if len(refs) > 1:\n",
    "            prompt += f\"Reference Doc 2:\\n{refs[1]}\\n\"\n",
    "        prompt += \"Return a JSON array of questions.\"\n",
    "\n",
    "        # from ollama import chat\n",
    "        # from ollama import ChatResponse\n",
    "\n",
    "        # response: ChatResponse = chat(model='qwen3:8b', \n",
    "        #                                messages=[\n",
    "        #         {\"role\": \"system\", \"content\": System_prompt},\n",
    "        #         {\"role\": \"user\", \"content\": prompt}\n",
    "        #     ])\n",
    "        # # print(response['message']['content'])\n",
    "        # # or access fields directly from the response object\n",
    "        # print(response.message.content)\n",
    "        # content = response.message.content\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": System_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        content = response.choices[0].message.content\n",
    "        \n",
    "        try:\n",
    "            # Clean and extract JSON from the output\n",
    "            json_str = extract_json_from_text(content)\n",
    "            questions = json.loads(json_str)\n",
    "            if not isinstance(questions, list):\n",
    "                # If the output is an object with a questions key\n",
    "                if isinstance(questions, dict) and \"questions\" in questions:\n",
    "                    questions = questions[\"questions\"]\n",
    "                else:\n",
    "                    questions = [str(questions)]\n",
    "        except json.JSONDecodeError:\n",
    "            questions = [content]\n",
    "\n",
    "        results.append({\n",
    "            \"id\": combo_id,\n",
    "            \"topics\": combo['topics'],\n",
    "            \"key_concepts\": combo['key_concepts'],\n",
    "            \"reference_files\": ref_files,\n",
    "            \"questions\": questions\n",
    "        })\n",
    "        max_samples-=1\n",
    "        if max_samples == 0:\n",
    "            break\n",
    "\n",
    "\n",
    "    return results\n",
    "\n",
    "# -- Save outputs to files ------------------------------------------------\n",
    "\n",
    "def save_extractions(extractions, output_file=\"document_extractions.json\"):\n",
    "    \"\"\"Save the extracted topics and key concepts for each document\"\"\"\n",
    "    # Ensure the extractions are serializable (convert sets to lists)\n",
    "    serializable_extractions = []\n",
    "    for ex in extractions:\n",
    "        serializable_extractions.append({\n",
    "            \"filename\": ex[\"filename\"],\n",
    "            \"topics\": list(ex[\"topics\"]),\n",
    "            \"key_concepts\": list(ex[\"key_concepts\"])\n",
    "        })\n",
    "    \n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(serializable_extractions, f, indent=2)\n",
    "    \n",
    "    print(f\"Saved document extractions to {output_file}\")\n",
    "\n",
    "def save_questions_with_topics(questions, output_file=\"questions_with_topics.json\"):\n",
    "    \"\"\"Save the generated questions with their topic combinations\"\"\"\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(questions, f, indent=2)\n",
    "    \n",
    "    print(f\"Saved questions with topic combinations to {output_file}\")\n",
    "\n",
    "# -- Main Execution --------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir = \"output_chemistry\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # adjust this path to where your .pdf docs live\n",
    "    docs_dir = \"data/\"\n",
    "    \n",
    "    print(\"Loading documents...\")\n",
    "    docs, filenames = load_docs_from_dir(docs_dir)\n",
    "    print(f\"Loaded {len(docs)} documents\")\n",
    "    \n",
    "    if not docs:\n",
    "        print(\"No documents found. Please check the docs directory.\")\n",
    "        exit(1)\n",
    "    \n",
    "    # 1) Extract topics & KCs\n",
    "    print(\"\\nExtracting topics and key concepts...\")\n",
    "    extractions = extract_concepts_from_docs(docs, filenames)\n",
    "    \n",
    "    # Save extractions to file\n",
    "    save_extractions(extractions, os.path.join(output_dir, \"document_extractions_chemistry.json\"))\n",
    "    \n",
    "    # Verify we have valid extractions\n",
    "    valid_extractions = [ex for ex in extractions if ex[\"topics\"] or ex[\"key_concepts\"]]\n",
    "    if not valid_extractions:\n",
    "        print(\"No valid topics or key concepts extracted. Check your data and API responses.\")\n",
    "        exit(1)\n",
    "    \n",
    "    # 2) Build graph\n",
    "    print(\"\\nBuilding concept graph...\")\n",
    "    G, topic_nodes, kc_nodes = build_concept_graph(extractions)\n",
    "    \n",
    "    if not topic_nodes:\n",
    "        print(\"No topics found in the graph. Cannot proceed.\")\n",
    "        exit(1)\n",
    "    \n",
    "    # 3) Sample combinations\n",
    "    print(\"\\nSampling concept combinations...\")\n",
    "    combos = sample_concept_combinations(G, topic_nodes, kc_nodes, num_samples=10)  # Reduced for testing\n",
    "    \n",
    "    if not combos:\n",
    "        print(\"Failed to generate concept combinations.\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Save topic combinations\n",
    "    with open(os.path.join(output_dir, \"topic_combinations_chemistry.json\"), \"w\") as f:\n",
    "        json.dump(combos, f, indent=2)\n",
    "    \n",
    "    # 4) Generate questions\n",
    "    # print(\"\\nGenerating questions for each combination...\")\n",
    "    # q_outputs = generate_questions_for_samples(combos, docs, extractions)\n",
    "    \n",
    "    # # Save questions with topics\n",
    "    # save_questions_with_topics(q_outputs, os.path.join(output_dir, \"questions_with_topics.json\"))\n",
    "    \n",
    "    # # Display results\n",
    "    # print(\"\\n===== GENERATED QUESTIONS =====\")\n",
    "    # for idx, out in enumerate(q_outputs, 1):\n",
    "    #     print(f\"\\nSample {idx}:\")\n",
    "    #     print(f\"Topics: {out['topics']}\")\n",
    "    #     print(f\"Key Concepts: {out['key_concepts']}\")\n",
    "    #     print(f\"Reference Files: {out['reference_files']}\")\n",
    "    #     print(\"Questions:\")\n",
    "    #     for q in out['questions']:\n",
    "    #         print(f\" - {q}\")\n",
    "    \n",
    "    # print(f\"\\nAll outputs saved to directory: {output_dir}\") \n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Create output directory if it doesn't exist\n",
    "#     # Create output directory if it doesn't exist\n",
    "#     output_dir = \"output_apple\"\n",
    "#     os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "#     # adjust this path to where your .pdf docs live\n",
    "#     docs_dir = \"docs/\"\n",
    "    \n",
    "#     print(\"Loading documents...\")\n",
    "#     docs, filenames = load_docs_from_dir(docs_dir)\n",
    "#     print(f\"Loaded {len(docs)} documents\")\n",
    "#     document_extractions = []\n",
    "#     with open(\"output_apple/document_extractions.json\", \"r\") as f:\n",
    "#         document_extractions = json.load(f)\n",
    "#     for doc in document_extractions:\n",
    "#         print(doc)\n",
    "#         break\n",
    "\n",
    "#     topic_combinations = []\n",
    "#     with open(\"output_apple/topic_combinations.json\", \"r\") as f:\n",
    "#         topic_combinations = json.load(f)\n",
    "#     for combo in topic_combinations:\n",
    "#         print(combo)\n",
    "#         break\n",
    "\n",
    "#     # generate questions \n",
    "#     print(\"Generating questions...\")\n",
    "#     q_outputs = generate_questions_for_samples(topic_combinations, docs, document_extractions)\n",
    "\n",
    "#     # Save questions with topics\n",
    "#     save_questions_with_topics(q_outputs, os.path.join(output_dir, \"questions_with_topics.json\"))\n",
    "    \n",
    "#     # Display results\n",
    "#     print(\"\\n===== GENERATED QUESTIONS =====\")\n",
    "#     for idx, out in enumerate(q_outputs, 1):\n",
    "#         print(f\"\\nSample {idx}:\")\n",
    "#         print(f\"Topics: {out['topics']}\")\n",
    "#         print(f\"Key Concepts: {out['key_concepts']}\")\n",
    "#         print(f\"Reference Files: {out['reference_files']}\")\n",
    "#         print(\"Questions:\")\n",
    "#         for q in out['questions']:\n",
    "#             print(f\" - {q}\")\n",
    "    \n",
    "#     print(f\"\\nAll outputs saved to directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/23] Downloaded → 1.pdf\n",
      "[2/23] Downloaded → 2.pdf\n",
      "[3/23] Downloaded → 3.pdf\n",
      "[4/23] Downloaded → 4.pdf\n",
      "[5/23] Downloaded → 5.pdf\n",
      "[6/23] Downloaded → 6.pdf\n",
      "[7/23] Downloaded → 7.pdf\n",
      "[8/23] Downloaded → 8.pdf\n",
      "[9/23] Downloaded → 9.pdf\n",
      "[10/23] Downloaded → 10.pdf\n",
      "[11/23] Downloaded → 11.pdf\n",
      "[12/23] Downloaded → 12.pdf\n",
      "[13/23] Downloaded → 13.pdf\n",
      "[14/23] Downloaded → 14.pdf\n",
      "[15/23] Downloaded → 15.pdf\n",
      "[16/23] Downloaded → 16.pdf\n",
      "[17/23] Downloaded → 17.pdf\n",
      "[18/23] Downloaded → 18.pdf\n",
      "[19/23] Downloaded → 19.pdf\n",
      "[20/23] Downloaded → 20.pdf\n",
      "[21/23] Downloaded → 21.pdf\n",
      "[22/23] FAILED  → https://arxiv.org/abs/2505.06432'\n",
      "    404 Client Error: Not Found for url: https://arxiv.org/abs/2505.06432'\n",
      "[23/23] Downloaded → 23.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import requests\n",
    "from urllib.parse import urlparse, unquote\n",
    "\n",
    "def download_files(\n",
    "    csv_path=\"Researchpapers_PhD_Synthetic_Data - chemistry.csv\",\n",
    "    output_dir=\"docs\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Reads a CSV with a 'Link' column and downloads each URL to output_dir,\n",
    "    saving each file with a .pdf extension.\n",
    "    \"\"\"\n",
    "    # Load CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if 'Link' not in df.columns:\n",
    "        raise ValueError(\"CSV must contain a 'Link' column.\")\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    total = len(df['Link'].dropna())\n",
    "    for idx, url in enumerate(df['Link'].dropna(), start=1):\n",
    "        try:\n",
    "            # Parse URL and derive a safe filename\n",
    "            parsed = urlparse(url)\n",
    "            raw_name = os.path.basename(parsed.path)\n",
    "            raw_name = unquote(raw_name)  # decode URL-encoded characters\n",
    "\n",
    "            if raw_name:\n",
    "                name, ext = os.path.splitext(raw_name)\n",
    "                # If there's no .pdf extension, force it\n",
    "                filename = f\"{idx}.pdf\" if ext.lower() != '.pdf' else raw_name\n",
    "            else:\n",
    "                filename = f\"{idx}.pdf\"\n",
    "\n",
    "            out_path = os.path.join(output_dir, filename)\n",
    "\n",
    "            # Stream download\n",
    "            with requests.get(url, stream=True) as r:\n",
    "                r.raise_for_status()\n",
    "                with open(out_path, 'wb') as f:\n",
    "                    for chunk in r.iter_content(chunk_size=8192):\n",
    "                        if chunk:\n",
    "                            f.write(chunk)\n",
    "\n",
    "            print(f\"[{idx}/{total}] Downloaded → {filename}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[{idx}/{total}] FAILED  → {url}\\n    {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    download_files()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author - Critique Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 300\u001b[0m\n\u001b[1;32m    297\u001b[0m     concepts \u001b[38;5;241m=\u001b[39m combo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey_concepts\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;66;03m# logger.info(f\"Processing combination: {topics} | {concepts}\")\u001b[39;00m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# Run the author–critic loop for this combination\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     questions \u001b[38;5;241m=\u001b[39m \u001b[43mauthor_critique_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtopics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcepts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguidelines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfew_shot_examples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_turns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m     all_questions\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: questions\n\u001b[1;32m    306\u001b[0m     })\n\u001b[1;32m    308\u001b[0m \u001b[38;5;66;03m# Save all questions to a file\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 91\u001b[0m, in \u001b[0;36mauthor_critique_loop\u001b[0;34m(topics, concepts, guidelines, few_shot_examples, max_turns, level)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# Turn 0: Generation\u001b[39;00m\n\u001b[1;32m     90\u001b[0m log(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== Turn 0: Author generates questions ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 91\u001b[0m questions_text \u001b[38;5;241m=\u001b[39m \u001b[43mauthor_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtopics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtopics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcepts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcepts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguidelines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mguidelines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m log(questions_text)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Turn 0: Critic feedback\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/_api/deprecation.py:191\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    190\u001b[0m     emit_warning()\n\u001b[0;32m--> 191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain/chains/base.py:608\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[1;32m    604\u001b[0m         _output_key\n\u001b[1;32m    605\u001b[0m     ]\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m--> 608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[1;32m    609\u001b[0m         _output_key\n\u001b[1;32m    610\u001b[0m     ]\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    613\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    614\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    615\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but none were provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    616\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/_api/deprecation.py:191\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    190\u001b[0m     emit_warning()\n\u001b[0;32m--> 191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain/chains/base.py:386\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \n\u001b[1;32m    356\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    379\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    384\u001b[0m }\n\u001b[0;32m--> 386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain/chains/base.py:167\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    166\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    168\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain/chains/base.py:157\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    156\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 157\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    162\u001b[0m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    163\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain/chains/llm.py:127\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_call\u001b[39m(\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    124\u001b[0m     inputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    125\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    126\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m--> 127\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain/chains/llm.py:139\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    137\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[1;32m    147\u001b[0m         cast(\u001b[38;5;28mlist\u001b[39m, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[1;32m    148\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py:947\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    940\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    945\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    946\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 947\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py:766\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    765\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 766\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    772\u001b[0m         )\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    774\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_core/language_models/chat_models.py:1012\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1012\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1016\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_community/chat_models/openai.py:476\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m    470\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[1;32m    471\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream} \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    475\u001b[0m }\n\u001b[0;32m--> 476\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletion_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_community/chat_models/openai.py:387\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[0;34m(self, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Use tenacity to retry the completion call.\"\"\"\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_openai_v1():\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m retry_decorator \u001b[38;5;241m=\u001b[39m _create_retry_decorator(\u001b[38;5;28mself\u001b[39m, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[1;32m    391\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/_utils/_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/resources/chat/completions.py:579\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    577\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    578\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 579\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/_base_client.py:1240\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1228\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1235\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1236\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1237\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1238\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1239\u001b[0m     )\n\u001b[0;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/_base_client.py:921\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    914\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    920\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/_base_client.py:952\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    949\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 952\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    958\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/httpx/_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/httpx/_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/httpx/_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    989\u001b[0m     hook(request)\n\u001b[0;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/httpx/_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1024\u001b[0m     )\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    245\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1226\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1223\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1224\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1225\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1101\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import uuid\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import logging\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, FewShotPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "def author_critique_loop(\n",
    "    topics: list[str],\n",
    "    concepts: list[str],\n",
    "    guidelines: str,\n",
    "    few_shot_examples: list[dict],\n",
    "    max_turns: int = 2,\n",
    "    level: str = \"advanced\"\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Runs an iterative author-critic loop to generate and refine chemistry questions.\n",
    "\n",
    "    Logs the entire multi-turn conversation (author + critic) to a single file.\n",
    "\n",
    "    Returns a list of dicts with:\n",
    "        unique_id: str,\n",
    "        question: str,\n",
    "        topics: list[str],\n",
    "        concepts: list[str],\n",
    "        file_conversation_log: str  # path to the full conversation log\n",
    "    \"\"\"\n",
    "    # Create a unique run-level conversation log\n",
    "    run_id = uuid.uuid4().hex\n",
    "    os.makedirs('logs', exist_ok=True)\n",
    "    conv_log_path = f\"logs/{run_id}.log\"\n",
    "    conv_logger = open(conv_log_path, 'w')\n",
    "\n",
    "    def log(msg: str):\n",
    "        conv_logger.write(msg + \"\\n\")\n",
    "        conv_logger.flush()\n",
    "\n",
    "    # Initialize LLMs (temperature locked to 1.0)\n",
    "    author_llm = ChatOpenAI(model_name=\"gpt-4.1-mini\", temperature=1.0)\n",
    "    critic_llm = ChatOpenAI(model_name=\"gpt-4.1\", temperature=1.0)\n",
    "    gemini_api = os.getenv(\"GEMINI_API_KEY\")\n",
    "    # critic_llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-preview-05-20\", temperature=1.0,google_api_key=gemini_api)\n",
    "    # Build Few-Shot prompt for author\n",
    "    example_prompt = PromptTemplate(\n",
    "        input_variables=[\"example\"],\n",
    "        template=\"Example:\\n{example}\\n---\"\n",
    "    )\n",
    "    author_fs_prompt = FewShotPromptTemplate(\n",
    "        examples=few_shot_examples,\n",
    "        example_prompt=example_prompt,\n",
    "        prefix=(\n",
    "            \"You are a Chemistry education specialist. Generate novel {level} chemistry questions. \"\n",
    "            \"Each question must start with <question> and end with </question>. Here are examples:\"\n",
    "        ),\n",
    "        suffix=(\n",
    "            \"Now, based on the topics: {topics}, key concepts: {concepts}, and guidelines: {guidelines}, \"\n",
    "            \"produce list of new, high-quality chemistry questions, each wrapped in <question>...</question> tags.\"\n",
    "        ),\n",
    "        input_variables=[\"topics\", \"concepts\", \"guidelines\",\"level\"],\n",
    "    )\n",
    "    author_chain = LLMChain(llm=author_llm, prompt=author_fs_prompt)\n",
    "\n",
    "    # Build Critic prompt\n",
    "    critic_prompt = PromptTemplate(\n",
    "        input_variables=[\"questions\", \"guidelines\"],\n",
    "        template=(\n",
    "            \"You are a chemistry assessment expert. Critique the following questions:\\n\"\n",
    "            \"{questions}\\n\"\n",
    "            \"Evaluate them against these guidelines:\\n{guidelines}\\n\"\n",
    "            \"Provide concise, actionable feedback on how to improve.\"\n",
    "        ),\n",
    "    )\n",
    "    critic_chain = LLMChain(llm=critic_llm, prompt=critic_prompt)\n",
    "\n",
    "    # Turn 0: Generation\n",
    "    log(\"=== Turn 0: Author generates questions ===\")\n",
    "    questions_text = author_chain.run(\n",
    "        topics=topics, concepts=concepts, guidelines=guidelines, level=level\n",
    "    )\n",
    "    log(questions_text)\n",
    "\n",
    "    # Turn 0: Critic feedback\n",
    "    log(\"=== Turn 0: Critic feedback ===\")\n",
    "    feedback = critic_chain.run(questions=questions_text, guidelines=guidelines)\n",
    "    log(feedback)\n",
    "\n",
    "    # Refinement turns\n",
    "    for turn in range(1, max_turns):\n",
    "        log(f\"=== Turn {turn}: Author refines questions ===\")\n",
    "        refine_prompt = PromptTemplate(\n",
    "            input_variables=[\"questions\", \"feedback\"],\n",
    "            template=(\n",
    "                \"Refine these questions based on the feedback:\\n{questions}\\n\"\n",
    "                \"Feedback:\\n{feedback}\\n\"\n",
    "                \"Return an improved numbered list of chemistry questions, each wrapped in <question>...</question> tags.\"\n",
    "            ),\n",
    "        )\n",
    "        refine_chain = LLMChain(llm=author_llm, prompt=refine_prompt)\n",
    "        questions_text = refine_chain.run(questions=questions_text, feedback=feedback)\n",
    "        log(questions_text)\n",
    "        if turn == max_turns - 1:\n",
    "            log(\"=== Final questions generated ===\")\n",
    "            break\n",
    "        log(f\"=== Turn {turn}: Critic feedback ===\")\n",
    "        feedback = critic_chain.run(questions=questions_text, guidelines=guidelines)\n",
    "        log(feedback)\n",
    "\n",
    "    # Close the conversation log\n",
    "    conv_logger.close()\n",
    "\n",
    "    # Parse final questions into structured entries\n",
    "    entries: list[dict] = []\n",
    "    pattern = re.compile(r'<question>(.*?)</question>', re.DOTALL)\n",
    "    for match in pattern.findall(questions_text):\n",
    "        question_body = match.strip()\n",
    "        uid = uuid.uuid4().hex\n",
    "        entries.append({\n",
    "            \"unique_id\": uid,\n",
    "            \"level\": level,\n",
    "            \"topics\": topics,\n",
    "            \"concepts\": concepts,\n",
    "            \"question\": question_body,\n",
    "            \"file_conversation_log\": conv_log_path\n",
    "        })\n",
    "        print(f\"Generated question: {question_body}\")\n",
    "\n",
    "    return entries\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Chemistry-specific example usage\n",
    "    # topics = [\n",
    "    #     \"Thermodynamics of Chemical Reactions\",\n",
    "    #     \"Organic Reaction Mechanisms\",\n",
    "    #     \"Coordination Chemistry\",\n",
    "    #     \"Electrochemical Cells\"\n",
    "    # ]\n",
    "    # concepts = [\n",
    "    #     \"Use of enthalpy, entropy, and Gibbs free energy to predict reaction spontaneity.\",\n",
    "    #     \"Mechanistic steps in nucleophilic substitution and elimination reactions.\",\n",
    "    #     \"Formation constants and isomerism in transition metal complexes.\",\n",
    "    #     \"Calculating cell potential using standard reduction potentials and Nernst equation.\"\n",
    "    # ]\n",
    "    with open(\"output_chemistry/topic_combinations_chemistry.json\", \"r\") as f:\n",
    "        topic_combinations = json.load(f)\n",
    "    \n",
    "    # make topic combination a list conatainin only the 3rd element\n",
    "    # topic_combinations = [combo['topics'] for combo in topic_combinations]\n",
    "    topic_combinations = [topic_combinations[5]] # Limit to first 10 for testing\n",
    "    # guidelines = (\n",
    "    #     \"1. Model a Chemistry Scenario: Start from a real-world or idealized setup.\"\n",
    "    #     \"2. Expect answers as numerical values with appropriate units or chemical compounds named using official IUPAC nomenclature. \"\n",
    "    #     \"3. Force Multi-Step Reasoning: Ensure calculations or mechanistic steps are detailed. \"\n",
    "    #     \"4. Avoid Redundancy: Exclude extraneous information that does not affect the answer. \"\n",
    "    #     \"5. Be Unique: Do not repeat standard textbook examples; ensure originality and complexity. \"\n",
    "    #     \"6. Single solution: Provide one correct numerical value or compound name. \"\n",
    "    #     \"7. Use rigorous, concise phrasing. \"\n",
    "    #     \"8. Avoid colloquial or ambiguous terminology. \"\n",
    "    #     \"9. Units must be consistent; chemical nomenclature must follow IUPAC rules.\"\n",
    "    #     \"10. Questions must not have multiple parts to answer, there should be only 1 solution to each question\"\n",
    "    #     \"11. give the final question in inline markdown snippet code using $ instead of # for the purpose of rendering\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # )\n",
    "    #make a enum of level \n",
    "    levels = [\"easy\", \"medium\", \"hard\"]\n",
    "    level = \"hard\"  # Change this to \"high school\", \"college\", or \"phd\" as needed\n",
    "    if level not in levels:\n",
    "        raise ValueError(f\"Invalid level: {level}. Must be one of {levels}.\")\n",
    "    # Example few-shot examples\n",
    "    # Note: These examples should be tailored to the specific level of difficulty\n",
    "\n",
    "    if level == \"easy\":\n",
    "        few_shot_examples = [\n",
    "            {\"example\": (\n",
    "                r\"\"\"Good: SN1 glycosylation selectivity (one decimal place)  \n",
    "A 4,6-O-benzylidene-protected α-D-glucopyranosyl trichloroacetimidate donor undergoes SN1 glycosylation in CH₂Cl₂ at 298 K.  DFT gives  \n",
    " ΔG‡α = 85.8 kJ·mol⁻¹  \n",
    " ΔG‡β = 93.3 kJ·mol⁻¹  \n",
    "\n",
    "The ratio of product mole fractions is  \n",
    " Pα/Pβ = exp[(ΔG‡β – ΔG‡α)/(R T)].  \n",
    "\n",
    "Calculate the α : β ratio in the form X : 1.  \n",
    "Report the value of X (α/β) to one decimal place.  \"\"\"\n",
    "            )},\n",
    "            {\"example\": (\n",
    "                r\"Bad: What is the pH of a solution?\"\n",
    "            )},\n",
    "        ]\n",
    "        #easy guidlines\n",
    "        guidelines = (\n",
    "    r\"1. Model a Chemistry Scenario: Start from a clear but very simple real-world or textbook-style setup.\"\n",
    "    r\"2. Expect answers as single numerical values with correct units **or** a single compound name in official IUPAC nomenclature. \"\n",
    "    r\"3. Single-Step Calculation: The question should require at most one direct substitution into a standard formula or one straightforward fact recall. \"\n",
    "    r\"4. Avoid Redundancy: Provide only the data strictly needed for that one calculation or fact. \"\n",
    "    r\"5. Be Unique: Even simple, the context should not be copied verbatim from common examples. \"\n",
    "    r\"6. Single solution: Provide exactly one correct numerical value or compound name. \"\n",
    "    r\"7. Use rigorous, concise phrasing. \"\n",
    "    r\"8. Avoid colloquial or ambiguous terminology. \"\n",
    "    r\"9. Units must be consistent; chemical nomenclature must follow IUPAC rules. \"\n",
    "    r\"10. Questions must not have multiple parts; a single answer is expected. \"\n",
    "    r\"11. Solution Formatting: Format equations, numbers and variables using LaTeX with Markdown syntax: \"\n",
    "    r\"Replace \\\\(...\\\\) with $...$ \"\n",
    "    r\"Replace \\\\[...\\\\] with $$...$$ \"\n",
    "    r\"Example $c = 0.10\\\\,\\\\mathrm{mol\\\\,L^{-1}}$, $\\\\Delta H = -57\\\\,\\\\mathrm{kJ\\\\,mol^{-1}}$\"\n",
    ")\n",
    "    elif level == \"medium\":\n",
    "        few_shot_examples = [\n",
    "            {\"example\": (\n",
    "                r\"\"\"Good:  Half-life of intramolecular cyclization (two significant figures)  \n",
    "A 4,6-O-benzylidene-protected D-galactopyranosyl oxocarbenium ion cyclizes intramolecularly via O4→C1 with ΔG‡ = 59.4 kJ·mol⁻¹ (convert to J·mol⁻¹ before use) at 298 K.  Using  \n",
    "\n",
    " k = (kB T/h) exp(–ΔG‡/(R T))  \n",
    " t₁/₂ = (ln 2)/k  \n",
    "\n",
    "calculate the half-life t₁/₂ in seconds at 298 K.  Report t₁/₂ to two significant figures. \"\"\"\n",
    "            )},\n",
    "            {\"example\": (\n",
    "                r\"Bad: Define molarity.\"\n",
    "            )},\n",
    "        ]\n",
    "        #medium guidelines\n",
    "        guidelines = (\n",
    "    r\"1. Model a Chemistry Scenario: Start from a real-world or idealized setup that may involve a short descriptive context, diagram or simple data table. \"\n",
    "    r\"2. Expect answers as numerical values with appropriate units **or** compound names in official IUPAC nomenclature. \"\n",
    "    r\"3. Moderate Reasoning: Require 2–3 logical or computational steps — e.g., selecting the correct formula, performing a stoichiometric ratio, or interpreting a simple graph. \"\n",
    "    r\"4. Provide only necessary data; remove any fluff that doesn’t influence the outcome. \"\n",
    "    r\"5. Be Unique: Avoid rehashing textbook end-of-chapter questions while staying at an intermediate difficulty. \"\n",
    "    r\"6. Single solution: Provide one correct numerical value or compound name. \"\n",
    "    r\"7. Use rigorous, concise phrasing. \"\n",
    "    r\"8. Avoid colloquial or ambiguous terminology. \"\n",
    "    r\"9. Units must be consistent; chemical nomenclature must follow IUPAC rules. \"\n",
    "    r\"10. Questions must not have multiple parts; produce only one final answer. \"\n",
    "    r\"11. Solution Formatting: Format equations, numbers and variables using LaTeX with Markdown syntax: \"\n",
    "    r\"Replace \\\\(...\\\\) with $...$ \"\n",
    "    r\"Replace \\\\[...\\\\] with $$...$$ \"\n",
    "    r\"Example $K_{\\\\mathrm{eq}} = 4.0 \\\\times 10^{-3}$, $pK_a = 2.15$\"\n",
    ")\n",
    "    elif level == \"hard\":\n",
    "        few_shot_examples = [\n",
    "        {\"example\": (\n",
    "            r\"\"\"Good: Solvent-dependent rate equality (three significant figures)  \n",
    "The same donor has activation free energies at 298 K:  \n",
    " ΔG‡(CH₂Cl₂) = 96.3 kJ·mol⁻¹  \n",
    " ΔG‡(MeCN)   = 89.9 kJ·mol⁻¹  \n",
    "\n",
    "According to the Eyring equation  \n",
    " k = (kB T/h) exp(–ΔG‡/(R T)),  \n",
    "\n",
    "neglect the temperature variation of the pre-exponential factor (treat kB T/h as equal in both rate constants).  Find the temperature T (in K) at which  \n",
    " k_CH₂Cl₂(T) = k_MeCN(298 K).  \"\"\"\n",
    "        )},\n",
    "        {\"example\": (\n",
    "            r\"Bad: Define enthalpy.\"\n",
    "        )},\n",
    "        ]\n",
    "        #hard guidelines\n",
    "        # ----------  (Existing hard-level guidelines remain unchanged)  ----------\n",
    "        guidelines = (\n",
    "    r\"1. Model a Chemistry Scenario: Start from a real-world or idealized setup.\"\n",
    "    r\"2. Expect answers as numerical values with appropriate units or chemical compounds named using official IUPAC nomenclature. \"\n",
    "    r\"3. Force Multi-Step Reasoning: Ensure calculations or mechanistic steps are detailed. \"\n",
    "    r\"4. Avoid Redundancy: Exclude extraneous information that does not affect the answer. \"\n",
    "    r\"5. Be Unique: Do not repeat standard textbook examples; ensure originality and complexity. \"\n",
    "    r\"6. Single solution: Provide one correct numerical value or compound name. \"\n",
    "    r\"7. Use rigorous, concise phrasing. \"\n",
    "    r\"8. Avoid colloquial or ambiguous terminology. \"\n",
    "    r\"9. Units must be consistent; chemical nomenclature must follow IUPAC rules.\"\n",
    "    r\"10. Questions must not have multiple parts to answer, there should be only 1 solution to each question\"\n",
    "    r\"11. Solution Formatting: Format the equations, numbers and variables using LaTeX with Markdown syntax: \"\n",
    "    r\"Replace \\\\(...\\\\) with $...$ \"\n",
    "    r\"Replace \\\\[...\\\\] with $$...$$ \"\n",
    "    r\"the questions must be renderable in Markdown, so use $ for inline math and $$ for block math. \"\n",
    "    r\"Example:  $F = ma$   and   $$E = mc^2$$.\"\n",
    ")\n",
    "    all_questions = []\n",
    "\n",
    "    for combo in topic_combinations:\n",
    "        topics = combo['topics']\n",
    "        concepts = combo['key_concepts']\n",
    "        # logger.info(f\"Processing combination: {topics} | {concepts}\")\n",
    "        # Run the author–critic loop for this combination\n",
    "        questions = author_critique_loop(\n",
    "            topics, concepts, guidelines, few_shot_examples, max_turns=4, level=level\n",
    "        )\n",
    "        \n",
    "        all_questions.append({\n",
    "            \"data\": questions\n",
    "        })\n",
    "\n",
    "    # Save all questions to a file\n",
    "    with open(\"final_questions_chemistry.json\", \"w\") as f:\n",
    "        json.dump(all_questions, f, indent=2)\n",
    "    \n",
    "    # 2) write a Markdown file you can grab directly\n",
    "    with open(\"final_questions_chemistry.md\", \"w\") as md:\n",
    "        for batch in all_questions:\n",
    "            for q in batch[\"data\"]:\n",
    "                # Write the question with its unique ID and topics\n",
    "                md.write(f\"### Question ID: {q['unique_id']}\\n\")\n",
    "                # Write the question text\n",
    "                md.write(\"**Question:**\\n\")\n",
    "            # q[\"question\"] already contains things like $\\theta$\n",
    "                md.write(q[\"question\"] + \"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 2) write a Markdown file you can grab directly\n",
    "with open(\"final_questions_chemistry.md\", \"w\") as md:\n",
    "        for batch in all_questions:\n",
    "            for q in batch[\"data\"]:\n",
    "                # Write the question with its unique ID and topics\n",
    "                md.write(f\"### Question ID: {q['unique_id']}\\n\")\n",
    "                # Write the question text\n",
    "                md.write(\"**Question:**\\n\")\n",
    "            # q[\"question\"] already contains things like $\\theta$\n",
    "                md.write(q[\"question\"] + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converting json to readable txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find the angle $\\theta$ such that $\\sin \\theta = 0.5$.\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"question\": r\"Find the angle $\\theta$ such that $\\sin \\theta = 0.5$.\"\n",
    "}\n",
    "\n",
    "with open(\"out.json\", \"w\") as f:\n",
    "    json.dump(data, f, indent=2)\n",
    "\n",
    "#load the json and print the question\n",
    "with open(\"out.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    print(data[\"question\"])  # Output: Find the angle $\\theta$ such that $\\sin \\theta = 0.5$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the question to a file .md\n",
    "with open(\"question.md\", \"w\") as f:\n",
    "    f.write(data[\"question\"])  # Output: Find the angle $\\theta$ such that $\\sin \\theta = 0.5$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
